{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf saved_lifter_2d_3d_model/synthetic_cabin_bw/A_Pillar_Codriver/prediction/linear_model/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tk/Documents/Projects/pose_estimation_3d/demo/repnet/repnet_linear_with_2d_predict_drive_and_act.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/demo/repnet/repnet_linear_with_2d_predict_drive_and_act.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/demo/repnet/repnet_linear_with_2d_predict_drive_and_act.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/demo/repnet/repnet_linear_with_2d_predict_drive_and_act.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m _dependency \u001b[39min\u001b[39;00m _hard_dependencies:\n\u001b[1;32m     10\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[39m__import__\u001b[39;49m(_dependency)\n\u001b[1;32m     12\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m _e:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         _missing_dependencies\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_dependency\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m_e\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/__init__.py:141\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m# Allow distributors to run custom init code\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init\n\u001b[0;32m--> 141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/__init__.py:105\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m# add these for module-freeze analysis (like PyInstaller)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _dtype_ctypes\n\u001b[0;32m--> 105\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _internal\n\u001b[1;32m    106\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _dtype\n\u001b[1;32m    107\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _methods\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_internal.py:145\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m ndarray\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(subtype, shape, dtype)\n\u001b[1;32m    143\u001b[0m \u001b[39m# format_re was originally from numarray by J. Todd Miller\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m format_re \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49mcompile(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m(?P<order1>[<>|=]?)\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    146\u001b[0m                        \u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m(?P<repeats> *[(]?[ ,0-9]*[)]? *)\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    147\u001b[0m                        \u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m(?P<order2>[<>|=]?)\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    148\u001b[0m                        \u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m(?P<dtype>[A-Za-z0-9.?]*(?:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m[[a-zA-Z0-9,.]+\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m])?)\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    149\u001b[0m sep_re \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*,\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    150\u001b[0m space_re \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+$\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/re.py:251\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(pattern, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/re.py:303\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sre_compile\u001b[39m.\u001b[39misstring(pattern):\n\u001b[1;32m    302\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfirst argument must be string or compiled pattern\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 303\u001b[0m p \u001b[39m=\u001b[39m sre_compile\u001b[39m.\u001b[39;49mcompile(pattern, flags)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (flags \u001b[39m&\u001b[39m DEBUG):\n\u001b[1;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_cache) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m _MAXCACHE:\n\u001b[1;32m    306\u001b[0m         \u001b[39m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/sre_compile.py:788\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mif\u001b[39;00m isstring(p):\n\u001b[1;32m    787\u001b[0m     pattern \u001b[39m=\u001b[39m p\n\u001b[0;32m--> 788\u001b[0m     p \u001b[39m=\u001b[39m sre_parse\u001b[39m.\u001b[39;49mparse(p, flags)\n\u001b[1;32m    789\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     pattern \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/sre_parse.py:955\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    952\u001b[0m state\u001b[39m.\u001b[39mstr \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\n\u001b[1;32m    954\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     p \u001b[39m=\u001b[39m _parse_sub(source, state, flags \u001b[39m&\u001b[39;49m SRE_FLAG_VERBOSE, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m    956\u001b[0m \u001b[39mexcept\u001b[39;00m Verbose:\n\u001b[1;32m    957\u001b[0m     \u001b[39m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[39m# on the safe side, we'll parse the whole thing again...\u001b[39;00m\n\u001b[1;32m    959\u001b[0m     state \u001b[39m=\u001b[39m State()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/sre_parse.py:444\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    442\u001b[0m start \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mtell()\n\u001b[1;32m    443\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    445\u001b[0m                        \u001b[39mnot\u001b[39;49;00m nested \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m items))\n\u001b[1;32m    446\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sourcematch(\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    447\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/sre_parse.py:841\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(err\u001b[39m.\u001b[39mmsg, \u001b[39mlen\u001b[39m(name) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    839\u001b[0m sub_verbose \u001b[39m=\u001b[39m ((verbose \u001b[39mor\u001b[39;00m (add_flags \u001b[39m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    840\u001b[0m                \u001b[39mnot\u001b[39;00m (del_flags \u001b[39m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[0;32m--> 841\u001b[0m p \u001b[39m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    842\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m source\u001b[39m.\u001b[39mmatch(\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    843\u001b[0m     \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mmissing ), unterminated subpattern\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    844\u001b[0m                        source\u001b[39m.\u001b[39mtell() \u001b[39m-\u001b[39m start)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/sre_parse.py:444\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    442\u001b[0m start \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mtell()\n\u001b[1;32m    443\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    445\u001b[0m                        \u001b[39mnot\u001b[39;49;00m nested \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m items))\n\u001b[1;32m    446\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sourcematch(\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    447\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/sre_parse.py:841\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(err\u001b[39m.\u001b[39mmsg, \u001b[39mlen\u001b[39m(name) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    839\u001b[0m sub_verbose \u001b[39m=\u001b[39m ((verbose \u001b[39mor\u001b[39;00m (add_flags \u001b[39m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    840\u001b[0m                \u001b[39mnot\u001b[39;00m (del_flags \u001b[39m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[0;32m--> 841\u001b[0m p \u001b[39m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    842\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m source\u001b[39m.\u001b[39mmatch(\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    843\u001b[0m     \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mmissing ), unterminated subpattern\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    844\u001b[0m                        source\u001b[39m.\u001b[39mtell() \u001b[39m-\u001b[39m start)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/sre_parse.py:444\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    442\u001b[0m start \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mtell()\n\u001b[1;32m    443\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    445\u001b[0m                        \u001b[39mnot\u001b[39;49;00m nested \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m items))\n\u001b[1;32m    446\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sourcematch(\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    447\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/sre_parse.py:549\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     this \u001b[39m=\u001b[39m sourceget()\n\u001b[0;32m--> 549\u001b[0m     \u001b[39mif\u001b[39;00m this \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39munterminated character set\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    551\u001b[0m                            source\u001b[39m.\u001b[39mtell() \u001b[39m-\u001b[39m here)\n\u001b[1;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m this \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mset\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.modules.lifter_2d_3d.model.linear_model.linear_model import BaselineModel\n",
    "from src.modules.lifter_2d_3d.dataset.simple_keypoint_dataset import SimpleKeypointDataset\n",
    "from src.modules.lifter_2d_3d.model.repnet.lit_repnet import LitRepNet\n",
    "from src.modules.utils.visualization import generate_connection_line, get_sample_from_loader, visualize_pose\n",
    "from IPython.display import display\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "\n",
    "train_dataset = SimpleKeypointDataset(\n",
    "    # prediction_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_train.json\",\n",
    "    # annotation_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_train.json\",\n",
    "    prediction_file=\"/root/data/processed/drive_and_act_train_with_vp1/keypoint_detection_results/keypoint_detection_train.json\",\n",
    "    annotation_file=\"/root/data/processed/drive_and_act_train_with_vp1/annotations/person_keypoints_train.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True,\n",
    "    exclude_knee=True\n",
    ")\n",
    "val_dataset = SimpleKeypointDataset(\n",
    "    # prediction_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_val.json\",\n",
    "    # annotation_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_val.json\",\n",
    "    prediction_file=\"/root/data/processed/drive_and_act_train_with_vp1/keypoint_detection_results/keypoint_detection_val.json\",\n",
    "    annotation_file=\"//root/data/processed/drive_and_act_train_with_vp1/annotations/person_keypoints_val.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True,\n",
    "    exclude_knee=True\n",
    ")\n",
    "test_dataset = SimpleKeypointDataset(\n",
    "    # prediction_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_test.json\",\n",
    "    # annotation_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_test.json\",\n",
    "    prediction_file=\"/root/data/processed/drive_and_act_train_with_vp1/keypoint_detection_results/keypoint_detection_test.json\",\n",
    "    annotation_file=\"/root/data/processed/drive_and_act_train_with_vp1/annotations/person_keypoints_test.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True,\n",
    "    exclude_knee=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    'train_dataset', len(train_dataset),\n",
    "    'val_dataset', len(val_dataset),\n",
    "    'test_dataset', len(test_dataset)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, drop_last=True, shuffle=True, num_workers=24)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, drop_last=True, num_workers=24)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=24)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss',mode='min', save_top_k=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "lifter_2D_3D = BaselineModel(exclude_ankle=True, exclude_knee=True)\n",
    "lit_model = LitRepNet(lifter_2D_3D=lifter_2D_3D)\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "saved_model_path = './saved_lifter_2d_3d_model/drive_and_act_train_with_vp1/prediction/repnet_linear_model/'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device', device)\n",
    "# device = 'cpu'\n",
    "trainer = pl.Trainer(\n",
    "    # max_steps=10,\n",
    "    max_epochs=500,\n",
    "    callbacks=[model_checkpoint, early_stopping],\n",
    "    accelerator=device,\n",
    "    check_val_every_n_epoch=10,\n",
    "    default_root_dir=saved_model_path,\n",
    "    # gradient_clip_val=1.0\n",
    ")\n",
    "trainer.fit(lit_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_checkpoint_path = model_checkpoint.best_model_path\n",
    "# trainer.test(ckpt_path=best_checkpoint_path, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample_from_loader(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in val_loader.dataset.samples:\n",
    "    if item['id'] == sample[0]:\n",
    "        print(item)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(f'/root/data/processed/drive_and_act_train_with_vp1/images/val/{item[\"filenames\"]}')\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "ax.scatter(item['keypoints2D'][:,0] * img.shape[0], item['keypoints2D'][:,1] * img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_keypoints = (sample[1].sum(axis=1) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_connection_line(sample[2],\n",
    "        np.argwhere(valid_keypoints).reshape(-1))\n",
    "pose_df = pd.DataFrame(results)\n",
    "visualize_pose(pose_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model.to(device)\n",
    "model.eval()\n",
    "estimated_pose = model.generator(torch.flatten(torch.tensor(sample[1])).unsqueeze(0).float().to(device))\n",
    "estimated_pose_df = pd.DataFrame(\n",
    "    generate_connection_line(\n",
    "        estimated_pose[1].cpu().reshape([-1, 3]).detach().numpy(),\n",
    "        # np.argwhere(valid_keypoints).reshape(-1)\n",
    "    )\n",
    ")\n",
    "visualize_pose(estimated_pose_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
