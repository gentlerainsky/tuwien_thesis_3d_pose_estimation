{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: saved_lifter_2d_3d_model/synthetic_cabin_bw/A_Pillar_Codriver/ground_truth/linear_model/lightning_logs\n",
      "\n",
      "  | Name  | Type          | Params\n",
      "----------------------------------------\n",
      "0 | model | BaselineModel | 4.3 M \n",
      "----------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.146    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset 37499 val_dataset 6250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07a4583b40b467bba4f5e2d535bdb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #0\n",
      "training loss from 0 batches: nan\n",
      "val loss from: 2 batches : 2677.553415298462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5b55ce403c4497bdb3374aeec1cc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ff41dd40f840ab9364e8e9ebec05e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #1\n",
      "training loss from 365 batches: 834.0025633981784\n",
      "val loss from: 12 batches : 413.78404200077057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6033eb8d39b0470ea98a92f25c257704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #2\n",
      "training loss from 365 batches: 308.3018910803207\n",
      "val loss from: 12 batches : 288.49173585573834\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc326783b174c608592c6409c4b93fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #3\n",
      "training loss from 365 batches: 180.4310951535016\n",
      "val loss from: 12 batches : 199.1114572932323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7939ad0dab5d422da0001ce0a0b31611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #4\n",
      "training loss from 365 batches: 125.35276231292175\n",
      "val loss from: 12 batches : 146.5978721777598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc19024942c41c5816f2e921d13a132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #5\n",
      "training loss from 365 batches: 100.2661989568031\n",
      "val loss from: 12 batches : 137.4981893847386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd24682df434391916c35be7f4d6f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #6\n",
      "training loss from 365 batches: 87.16506737552277\n",
      "val loss from: 12 batches : 135.23250073194504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95eea5ef8ae749cebf0e7563b17a17df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #7\n",
      "training loss from 365 batches: 80.54870781424927\n",
      "val loss from: 12 batches : 131.43510495622954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2f6597d2134f59aa3136a368c73f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #8\n",
      "training loss from 365 batches: 77.02695019032856\n",
      "val loss from: 12 batches : 132.89383674661318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b88490374b14fe6a7223eb6ec71fca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #9\n",
      "training loss from 365 batches: 76.0504697793967\n",
      "val loss from: 12 batches : 120.14082757135232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7507bd1540419ab2a2182e9c29a70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #10\n",
      "training loss from 365 batches: 71.29384467046555\n",
      "val loss from: 12 batches : 116.56017042696476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97868d74740b421bb6ee0dfdcd1144a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #11\n",
      "training loss from 365 batches: 67.72597639323914\n",
      "val loss from: 12 batches : 114.89594851930936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb25ed60c0141118de7975ddb4768b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #12\n",
      "training loss from 365 batches: 64.75481924741236\n",
      "val loss from: 12 batches : 107.52526919047038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cae45f9f504810a95939562a995aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #13\n",
      "training loss from 365 batches: 61.50648003979905\n",
      "val loss from: 12 batches : 104.68183799336354\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ccfc9ff4e94510bd572a87d2500e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #14\n",
      "training loss from 365 batches: 59.45301513149314\n",
      "val loss from: 12 batches : 102.15589217841625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32237d72b3740a69d09a823d03b7483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #15\n",
      "training loss from 365 batches: 57.43445317222647\n",
      "val loss from: 12 batches : 89.19459115713835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8915f5e6a3c24c4f840597067f013dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #16\n",
      "training loss from 365 batches: 57.14671405619138\n",
      "val loss from: 12 batches : 95.27363038311402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decd5f435f16417aad8bde1ebb1d3f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #17\n",
      "training loss from 365 batches: 54.537644165835964\n",
      "val loss from: 12 batches : 98.26637618243694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.modules.lifter_2d_3d.model.linear_model.linear_model import BaselineModel\n",
    "from src.modules.lifter_2d_3d.dataset.groundtruth_keypoint_dataset import GroundTruthKeypointDataset\n",
    "from src.modules.lifter_2d_3d.model.linear_model.lit_linear_model import LitSimpleBaselineLinear\n",
    "from IPython.display import display\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "\n",
    "# ------------\n",
    "# args\n",
    "# ------------\n",
    "# parser = ArgumentParser()\n",
    "# parser.add_argument('--batch_size', default=32, type=int)\n",
    "# parser.add_argument('--hidden_dim', type=int, default=128)\n",
    "# parser = pl.Trainer.add_argparse_args(parser)\n",
    "# parser = LitClassifier.add_model_specific_args(parser)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# ------------\n",
    "# data\n",
    "# ------------\n",
    "# dataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\n",
    "# mnist_test = MNIST('', train=False, download=True, transform=transforms.ToTensor())\n",
    "# mnist_train, mnist_val = random_split(dataset, [55000, 5000])\n",
    "\n",
    "train_dataset = GroundTruthKeypointDataset(\n",
    "    \"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_train.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "val_dataset = GroundTruthKeypointDataset(\n",
    "    \"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_val.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "print('train_dataset', len(train_dataset), 'val_dataset', len(val_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, drop_last=True)\n",
    "# test_loader = DataLoader(mnist_test, batch_size=args.batch_size)\n",
    "\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "# model = LitClassifier(Backbone(hidden_dim=args.hidden_dim), args.learning_rate)\n",
    "lit_model = LitSimpleBaselineLinear(exclude_ankle=True)\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "saved_model_path = './saved_lifter_2d_3d_model/synthetic_cabin_bw/A_Pillar_Codriver/ground_truth/linear_model/'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    # max_steps=10,\n",
    "    max_epochs=500,\n",
    "    # callbacks=[TQDMProgressBar(refresh_rate=5)],\n",
    "    # val_check_interval=10,\n",
    "    # accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    accelerator='cpu',\n",
    "    check_val_every_n_epoch=5,\n",
    "    default_root_dir=saved_model_path,\n",
    "    # gradient_clip_val=1.0\n",
    ")\n",
    "trainer.fit(lit_model, train_loader, val_loader)\n",
    "# ------------\n",
    "# testing\n",
    "# ------------\n",
    "# result = trainer.test(test_dataloaders=test_loader)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_connection_line(vals):\n",
    "    L = 0\n",
    "    C = 1\n",
    "    R = 2\n",
    "    connections = [\n",
    "        (0, 1, L, 'nose_left_eye'), # nose & left_eye\n",
    "        (0, 2, R, 'nose_right_eye'), # nose & right_eye\n",
    "        (1, 2, C, 'left_right_eye'), # left & right eyes\n",
    "        (1, 3, L, 'left_ear_left_eye'), # left ear & eye\n",
    "        (2, 4, R, 'right_ear_right_eye'), # right ear & eye\n",
    "        # (0, 5, L, 'nose_left_shoulder'), # nose & left shoulder\n",
    "        # (0, 6, R, 'nose_right_shoulder'), # nose & right shoulder\n",
    "        # (3, 5, L, 'left_ear_shoulder'), # left ear & shoulder\n",
    "        # (4, 6, R, 'right_ear_shoulder'), # right ear & shoulder\n",
    "        (5, 6, C, 'left_shoulder_right_sholder'), # left & right shoulder\n",
    "        (5, 7, L, 'left_sholder_left_elbow'), # left shoulder & elbow\n",
    "        (5, 11, L, 'left_shoulder_left_hip'), # left shoulder & hip\n",
    "        (6, 8, R, 'right_shoulder_right_elbow'), # right shoulder & elbow\n",
    "        (6, 12, R, 'right_shoulder_right_hip'), # right shoulder & hip\n",
    "        (7, 9, L, 'left_elbow_left_wrist'), # left elbow & wrist\n",
    "        (8, 10, R, 'right_elbow_right_wrist'), # right elbow & wrist\n",
    "        (11, 12, C, 'left_hip_right_hip'), # left & right hip\n",
    "        (11, 13, L, 'left_hip_left_knee'), # left hip & knee\n",
    "        (12, 14, R, 'right_hip_right_knee'), # right hip & knee\n",
    "        # (13, 15, L, 'left_knee_left_ankle'), # left knee & ankle\n",
    "        # (14, 16, R, 'right_knee_right_ankle') # right knee & ankle\n",
    "    ]\n",
    "    connection_lines = []\n",
    "\n",
    "    connection_count = 0\n",
    "    for i, connection in enumerate(connections):\n",
    "        x, y, z = [np.array([vals[connection[0], j], vals[connection[1], j]]) for j in range(3)]\n",
    "        for px, py, pz in zip(x, y, z):\n",
    "            connection_lines.append({\n",
    "                # \"line\": connection_count,\n",
    "                \"line\": connection[3],\n",
    "                \"left_right\": connection[2],\n",
    "                \"x\": px,\n",
    "                \"y\": py,\n",
    "                \"z\": pz\n",
    "            })\n",
    "        connection_count += 1\n",
    "    return connection_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = train_loader\n",
    "loader = val_loader\n",
    "sample = None\n",
    "count = 0\n",
    "item_index = 5\n",
    "for item in iter(loader):\n",
    "    sample = item\n",
    "    if (count + 1) % item_index == 0:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keypoint_df = pd.DataFrame({\n",
    "#     'name': train_dataset.metadata['keypoints'],\n",
    "#     'x': train_dataset.raw_data[0]['keypoints3D'][:, 0],\n",
    "#     'y': train_dataset.raw_data[0]['keypoints3D'][:, 1],\n",
    "#     'z': train_dataset.raw_data[0]['keypoints3D'][:, 2],\n",
    "# })\n",
    "results = generate_connection_line(sample[1][0].detach().numpy().reshape(-1, 3))\n",
    "pose_df = pd.DataFrame(results)\n",
    "\n",
    "fig = px.line_3d(pose_df, x=\"z\", y=\"x\", z=\"y\", color=\"line\")\n",
    "fig.update_layout(\n",
    "    scene={\n",
    "        'xaxis': {'autorange': 'reversed'}, # reverse automatically\n",
    "        'zaxis': {'autorange': 'reversed'},\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitSimpleBaselineLinear.load_from_checkpoint(\n",
    "    'saved_lifter_2d_3d_model/linear_model/lightning_logs/version_14/checkpoints/epoch=499-step=36500.ckpt'\n",
    ")\n",
    "model.eval()\n",
    "estimated_pose = model(sample[0].float().squeeze(2), 0)\n",
    "estimated_pose_df = pd.DataFrame(generate_connection_line(estimated_pose[0].reshape([-1, 3]).detach().numpy()))\n",
    "fig = px.line_3d(estimated_pose_df, x=\"z\", y=\"x\", z=\"y\", color=\"line\")\n",
    "fig.update_layout(\n",
    "    scene={\n",
    "        'xaxis': {'autorange': 'reversed'}, # reverse automatically\n",
    "        'zaxis': {'autorange': 'reversed'},\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\n",
    "#     'name': train_dataset.metadata['keypoints'],\n",
    "#     'keypoint3D_1': train_dataset[0]['keypoints3D'][:, 0],\n",
    "#     'keypoint3D_2': train_dataset[0]['keypoints3D'][:, 1],\n",
    "#     'keypoint3D_3': train_dataset[0]['keypoints3D'][:, 2],\n",
    "# })\n",
    "# left_eye = train_dataset[0]['keypoints3D'][2]\n",
    "# left_sholder = train_dataset[0]['keypoints3D'][5]\n",
    "# left_hip = train_dataset[0]['keypoints3D'][11]\n",
    "# left_knee = train_dataset[0]['keypoints3D'][13]\n",
    "# left_ankle = train_dataset[0]['keypoints3D'][15]\n",
    "\n",
    "# bone_length = lambda row1, row2: np.sqrt(np.sum((row2 - row1) ** 2))\n",
    "\n",
    "# ( \n",
    "#     bone_length(left_ankle, left_knee)\n",
    "#     + bone_length(left_knee, left_hip)\n",
    "#     + bone_length(left_hip, left_sholder)\n",
    "#     + bone_length(left_sholder, left_eye)\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
