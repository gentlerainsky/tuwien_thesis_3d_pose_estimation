{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.modules.lifter_2d_3d.model.linear_model.linear_model import BaselineModel\n",
    "from src.modules.lifter_2d_3d.dataset.simple_keypoint_dataset import SimpleKeypointDataset\n",
    "from src.modules.lifter_2d_3d.model.linear_model.lit_linear_model import LitSimpleBaselineLinear\n",
    "from IPython.display import display\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "\n",
    "# ------------\n",
    "# args\n",
    "# ------------\n",
    "# parser = ArgumentParser()\n",
    "# parser.add_argument('--batch_size', default=32, type=int)\n",
    "# parser.add_argument('--hidden_dim', type=int, default=128)\n",
    "# parser = pl.Trainer.add_argparse_args(parser)\n",
    "# parser = LitClassifier.add_model_specific_args(parser)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# ------------\n",
    "# data\n",
    "# ------------\n",
    "# dataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\n",
    "# mnist_test = MNIST('', train=False, download=True, transform=transforms.ToTensor())\n",
    "# mnist_train, mnist_val = random_split(dataset, [55000, 5000])\n",
    "\n",
    "train_dataset = SimpleKeypointDataset(\n",
    "    prediction_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_train.json\",\n",
    "    annotation_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_train.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "val_dataset = SimpleKeypointDataset(\n",
    "    prediction_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_val.json\",\n",
    "    annotation_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_val.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "print('train_dataset', len(train_dataset), 'val_dataset', len(val_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, drop_last=True)\n",
    "# test_loader = DataLoader(mnist_test, batch_size=args.batch_size)\n",
    "\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "# model = LitClassifier(Backbone(hidden_dim=args.hidden_dim), args.learning_rate)\n",
    "lit_model = LitSimpleBaselineLinear(exclude_ankle=True)\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "saved_model_path = './saved_lifter_2d_3d_model/synthetic_cabin_bw/A_Pillar_Codriver/prediction/linear_model/'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    # max_steps=10,\n",
    "    max_epochs=500,\n",
    "    # callbacks=[TQDMProgressBar(refresh_rate=5)],\n",
    "    # val_check_interval=10,\n",
    "    # accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    accelerator='cpu',\n",
    "    check_val_every_n_epoch=5,\n",
    "    default_root_dir=saved_model_path,\n",
    "    # gradient_clip_val=1.0\n",
    ")\n",
    "trainer.fit(lit_model, train_loader, val_loader)\n",
    "# ------------\n",
    "# testing\n",
    "# ------------\n",
    "# result = trainer.test(test_dataloaders=test_loader)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_connection_line(vals):\n",
    "    L = 0\n",
    "    C = 1\n",
    "    R = 2\n",
    "    connections = [\n",
    "        (0, 1, L, 'nose_left_eye'), # nose & left_eye\n",
    "        (0, 2, R, 'nose_right_eye'), # nose & right_eye\n",
    "        (1, 2, C, 'left_right_eye'), # left & right eyes\n",
    "        (1, 3, L, 'left_ear_left_eye'), # left ear & eye\n",
    "        (2, 4, R, 'right_ear_right_eye'), # right ear & eye\n",
    "        # (0, 5, L, 'nose_left_shoulder'), # nose & left shoulder\n",
    "        # (0, 6, R, 'nose_right_shoulder'), # nose & right shoulder\n",
    "        # (3, 5, L, 'left_ear_shoulder'), # left ear & shoulder\n",
    "        # (4, 6, R, 'right_ear_shoulder'), # right ear & shoulder\n",
    "        (5, 6, C, 'left_shoulder_right_sholder'), # left & right shoulder\n",
    "        (5, 7, L, 'left_sholder_left_elbow'), # left shoulder & elbow\n",
    "        (5, 11, L, 'left_shoulder_left_hip'), # left shoulder & hip\n",
    "        (6, 8, R, 'right_shoulder_right_elbow'), # right shoulder & elbow\n",
    "        (6, 12, R, 'right_shoulder_right_hip'), # right shoulder & hip\n",
    "        (7, 9, L, 'left_elbow_left_wrist'), # left elbow & wrist\n",
    "        (8, 10, R, 'right_elbow_right_wrist'), # right elbow & wrist\n",
    "        (11, 12, C, 'left_hip_right_hip'), # left & right hip\n",
    "        (11, 13, L, 'left_hip_left_knee'), # left hip & knee\n",
    "        (12, 14, R, 'right_hip_right_knee'), # right hip & knee\n",
    "        # (13, 15, L, 'left_knee_left_ankle'), # left knee & ankle\n",
    "        # (14, 16, R, 'right_knee_right_ankle') # right knee & ankle\n",
    "    ]\n",
    "    connection_lines = []\n",
    "\n",
    "    connection_count = 0\n",
    "    for i, connection in enumerate(connections):\n",
    "        x, y, z = [np.array([vals[connection[0], j], vals[connection[1], j]]) for j in range(3)]\n",
    "        for px, py, pz in zip(x, y, z):\n",
    "            connection_lines.append({\n",
    "                # \"line\": connection_count,\n",
    "                \"line\": connection[3],\n",
    "                \"left_right\": connection[2],\n",
    "                \"x\": px,\n",
    "                \"y\": py,\n",
    "                \"z\": pz\n",
    "            })\n",
    "        connection_count += 1\n",
    "    return connection_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = train_loader\n",
    "loader = val_loader\n",
    "sample = None\n",
    "count = 0\n",
    "item_index = 5\n",
    "for item in iter(loader):\n",
    "    sample = item\n",
    "    if (count + 1) % item_index == 0:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keypoint_df = pd.DataFrame({\n",
    "#     'name': train_dataset.metadata['keypoints'],\n",
    "#     'x': train_dataset.raw_data[0]['keypoints3D'][:, 0],\n",
    "#     'y': train_dataset.raw_data[0]['keypoints3D'][:, 1],\n",
    "#     'z': train_dataset.raw_data[0]['keypoints3D'][:, 2],\n",
    "# })\n",
    "results = generate_connection_line(sample[1][0].detach().numpy().reshape(-1, 3))\n",
    "pose_df = pd.DataFrame(results)\n",
    "\n",
    "fig = px.line_3d(pose_df, x=\"z\", y=\"x\", z=\"y\", color=\"line\")\n",
    "fig.update_layout(\n",
    "    scene={\n",
    "        'xaxis': {'autorange': 'reversed'}, # reverse automatically\n",
    "        'zaxis': {'autorange': 'reversed'},\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitSimpleBaselineLinear.load_from_checkpoint(\n",
    "    'saved_lifter_2d_3d_model/linear_model/lightning_logs/version_12/checkpoints/epoch=99-step=7300.ckpt'\n",
    ")\n",
    "model.eval()\n",
    "estimated_pose = model(sample[0].float().squeeze(2), 0)\n",
    "estimated_pose_df = pd.DataFrame(generate_connection_line(estimated_pose[0].reshape([-1, 3]).detach().numpy()))\n",
    "fig = px.line_3d(estimated_pose_df, x=\"z\", y=\"x\", z=\"y\", color=\"line\")\n",
    "fig.update_layout(\n",
    "    scene={\n",
    "        'xaxis': {'autorange': 'reversed'}, # reverse automatically\n",
    "        'zaxis': {'autorange': 'reversed'},\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\n",
    "#     'name': train_dataset.metadata['keypoints'],\n",
    "#     'keypoint3D_1': train_dataset[0]['keypoints3D'][:, 0],\n",
    "#     'keypoint3D_2': train_dataset[0]['keypoints3D'][:, 1],\n",
    "#     'keypoint3D_3': train_dataset[0]['keypoints3D'][:, 2],\n",
    "# })\n",
    "# left_eye = train_dataset[0]['keypoints3D'][2]\n",
    "# left_sholder = train_dataset[0]['keypoints3D'][5]\n",
    "# left_hip = train_dataset[0]['keypoints3D'][11]\n",
    "# left_knee = train_dataset[0]['keypoints3D'][13]\n",
    "# left_ankle = train_dataset[0]['keypoints3D'][15]\n",
    "\n",
    "# bone_length = lambda row1, row2: np.sqrt(np.sum((row2 - row1) ** 2))\n",
    "\n",
    "# ( \n",
    "#     bone_length(left_ankle, left_knee)\n",
    "#     + bone_length(left_knee, left_hip)\n",
    "#     + bone_length(left_hip, left_sholder)\n",
    "#     + bone_length(left_sholder, left_eye)\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
