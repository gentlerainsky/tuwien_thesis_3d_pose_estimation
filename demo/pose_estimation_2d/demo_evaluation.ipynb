{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/17 18:56:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 1288035136\n",
      "    GPU 0: NVIDIA TITAN Xp\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.99\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 2.0.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.8.2\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1288035136\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/17 18:56:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "default_scope = 'mmpose'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook', _scope_='mmpose'),\n",
      "    logger=dict(type='LoggerHook', interval=50, _scope_='mmpose'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook', _scope_='mmpose'),\n",
      "    checkpoint=dict(\n",
      "        type='CheckpointHook',\n",
      "        interval=10,\n",
      "        save_best='coco/AP',\n",
      "        rule='greater',\n",
      "        _scope_='mmpose'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook', _scope_='mmpose'),\n",
      "    visualization=dict(\n",
      "        type='PoseVisualizationHook', enable=False, _scope_='mmpose'))\n",
      "custom_hooks = [\n",
      "    dict(type='SyncBuffersHook', _scope_='mmpose'),\n",
      "]\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend', _scope_='mmpose'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='PoseLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "    ],\n",
      "    name='visualizer',\n",
      "    _scope_='mmpose')\n",
      "log_processor = dict(\n",
      "    type='LogProcessor',\n",
      "    window_size=50,\n",
      "    by_epoch=True,\n",
      "    num_digits=6,\n",
      "    _scope_='mmpose')\n",
      "log_level = 'INFO'\n",
      "load_from = 'mmengine_workdir/pose_estimator_2d/best_coco_AP_epoch_9.pth'\n",
      "resume = False\n",
      "backend_args = dict(backend='local')\n",
      "train_cfg = dict(by_epoch=True, max_epochs=10, val_interval=1)\n",
      "val_cfg = dict()\n",
      "test_cfg = dict()\n",
      "optim_wrapper = dict(optimizer=dict(type='Adam', lr=0.0005, _scope_='mmpose'))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='LinearLR',\n",
      "        begin=0,\n",
      "        end=500,\n",
      "        start_factor=0.001,\n",
      "        by_epoch=False,\n",
      "        _scope_='mmpose'),\n",
      "    dict(\n",
      "        type='MultiStepLR',\n",
      "        begin=0,\n",
      "        end=210,\n",
      "        milestones=[\n",
      "            170,\n",
      "            200,\n",
      "        ],\n",
      "        gamma=0.1,\n",
      "        by_epoch=True,\n",
      "        _scope_='mmpose'),\n",
      "]\n",
      "auto_scale_lr = dict(base_batch_size=512)\n",
      "codec = dict(\n",
      "    type='MSRAHeatmap',\n",
      "    input_size=(\n",
      "        192,\n",
      "        256,\n",
      "    ),\n",
      "    heatmap_size=(\n",
      "        48,\n",
      "        64,\n",
      "    ),\n",
      "    sigma=2,\n",
      "    _scope_='mmpose')\n",
      "model = dict(\n",
      "    type='TopdownPoseEstimator',\n",
      "    data_preprocessor=dict(\n",
      "        type='PoseDataPreprocessor',\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        bgr_to_rgb=True),\n",
      "    backbone=dict(\n",
      "        type='HRNet',\n",
      "        in_channels=3,\n",
      "        extra=dict(\n",
      "            stage1=dict(\n",
      "                num_modules=1,\n",
      "                num_branches=1,\n",
      "                block='BOTTLENECK',\n",
      "                num_blocks=(4, ),\n",
      "                num_channels=(64, )),\n",
      "            stage2=dict(\n",
      "                num_modules=1,\n",
      "                num_branches=2,\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                )),\n",
      "            stage3=dict(\n",
      "                num_modules=4,\n",
      "                num_branches=3,\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                )),\n",
      "            stage4=dict(\n",
      "                num_modules=3,\n",
      "                num_branches=4,\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                    256,\n",
      "                ))),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmpose/pretrain_models/hrnet_w32-36af842e.pth'\n",
      "        )),\n",
      "    head=dict(\n",
      "        type='HeatmapHead',\n",
      "        in_channels=32,\n",
      "        out_channels=17,\n",
      "        deconv_out_channels=None,\n",
      "        loss=dict(type='KeypointMSELoss', use_target_weight=True),\n",
      "        decoder=dict(\n",
      "            type='MSRAHeatmap',\n",
      "            input_size=(\n",
      "                192,\n",
      "                256,\n",
      "            ),\n",
      "            heatmap_size=(\n",
      "                48,\n",
      "                64,\n",
      "            ),\n",
      "            sigma=2)),\n",
      "    test_cfg=dict(flip_test=True, flip_mode='heatmap', shift_heatmap=True),\n",
      "    _scope_='mmpose')\n",
      "dataset_type = 'CocoDataset'\n",
      "data_mode = 'topdown'\n",
      "data_root = '/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver'\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImage', _scope_='mmpose'),\n",
      "    dict(type='GetBBoxCenterScale', _scope_='mmpose'),\n",
      "    dict(type='RandomFlip', direction='horizontal', _scope_='mmpose'),\n",
      "    dict(type='RandomHalfBody', _scope_='mmpose'),\n",
      "    dict(type='RandomBBoxTransform', _scope_='mmpose'),\n",
      "    dict(type='TopdownAffine', input_size=(\n",
      "        192,\n",
      "        256,\n",
      "    ), _scope_='mmpose'),\n",
      "    dict(\n",
      "        type='GenerateTarget',\n",
      "        encoder=dict(\n",
      "            type='MSRAHeatmap',\n",
      "            input_size=(\n",
      "                192,\n",
      "                256,\n",
      "            ),\n",
      "            heatmap_size=(\n",
      "                48,\n",
      "                64,\n",
      "            ),\n",
      "            sigma=2),\n",
      "        _scope_='mmpose'),\n",
      "    dict(type='PackPoseInputs', _scope_='mmpose'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='LoadImage', _scope_='mmpose'),\n",
      "    dict(type='GetBBoxCenterScale', _scope_='mmpose'),\n",
      "    dict(type='TopdownAffine', input_size=(\n",
      "        192,\n",
      "        256,\n",
      "    ), _scope_='mmpose'),\n",
      "    dict(type='PackPoseInputs', _scope_='mmpose'),\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=64,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True, _scope_='mmpose'),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver',\n",
      "        data_mode='topdown',\n",
      "        ann_file=\n",
      "        '/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_train.json',\n",
      "        data_prefix=dict(img='images/train'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImage'),\n",
      "            dict(type='GetBBoxCenterScale'),\n",
      "            dict(type='RandomFlip', direction='horizontal'),\n",
      "            dict(type='RandomHalfBody'),\n",
      "            dict(type='RandomBBoxTransform'),\n",
      "            dict(type='TopdownAffine', input_size=(\n",
      "                192,\n",
      "                256,\n",
      "            )),\n",
      "            dict(\n",
      "                type='GenerateTarget',\n",
      "                encoder=dict(\n",
      "                    type='MSRAHeatmap',\n",
      "                    input_size=(\n",
      "                        192,\n",
      "                        256,\n",
      "                    ),\n",
      "                    heatmap_size=(\n",
      "                        48,\n",
      "                        64,\n",
      "                    ),\n",
      "                    sigma=2)),\n",
      "            dict(type='PackPoseInputs'),\n",
      "        ],\n",
      "        _scope_='mmpose'))\n",
      "val_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(\n",
      "        type='DefaultSampler', shuffle=False, round_up=False,\n",
      "        _scope_='mmpose'),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver',\n",
      "        data_mode='topdown',\n",
      "        ann_file=\n",
      "        '/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_val.json',\n",
      "        bbox_file=\n",
      "        '/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/person_detection_results/human_detection_val.json',\n",
      "        data_prefix=dict(img='images/val'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImage'),\n",
      "            dict(type='GetBBoxCenterScale'),\n",
      "            dict(type='TopdownAffine', input_size=(\n",
      "                192,\n",
      "                256,\n",
      "            )),\n",
      "            dict(type='PackPoseInputs'),\n",
      "        ],\n",
      "        _scope_='mmpose'))\n",
      "test_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(\n",
      "        type='DefaultSampler', shuffle=False, round_up=False,\n",
      "        _scope_='mmpose'),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver',\n",
      "        data_mode='topdown',\n",
      "        ann_file=\n",
      "        '/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_test.json',\n",
      "        bbox_file=\n",
      "        '/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/person_detection_results/ground_truth_human_detection_test.json',\n",
      "        data_prefix=dict(img='images/test'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImage'),\n",
      "            dict(type='GetBBoxCenterScale'),\n",
      "            dict(type='TopdownAffine', input_size=(\n",
      "                192,\n",
      "                256,\n",
      "            )),\n",
      "            dict(type='PackPoseInputs'),\n",
      "        ],\n",
      "        _scope_='mmpose'))\n",
      "val_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file=\n",
      "    '/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_val.json',\n",
      "    _scope_='mmpose')\n",
      "test_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file=\n",
      "    '/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_test.json',\n",
      "    _scope_='mmpose')\n",
      "work_dir = 'mmengine_workdir/pose_estimator_2d'\n",
      "\n",
      "08/17 18:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/17 18:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) PoseVisualizationHook              \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) PoseVisualizationHook              \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by local backend from path: mmengine_workdir/pose_estimator_2d/best_coco_AP_epoch_9.pth\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmpose/datasets/datasets/utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/coco.py\" does not exist. A matched config file \"/opt/conda/lib/python3.10/site-packages/mmpose/.mim/configs/_base_/datasets/coco.py\" will be used instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Loads checkpoint by local backend from path: mmengine_workdir/pose_estimator_2d/best_coco_AP_epoch_9.pth\n",
      "08/17 18:56:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from mmengine_workdir/pose_estimator_2d/best_coco_AP_epoch_9.pth\n",
      "08/17 18:56:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 50/196]    eta: 0:00:34  time: 0.235402  data_time: 0.035444  memory: 584  \n",
      "08/17 18:56:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/196]    eta: 0:00:21  time: 0.220567  data_time: 0.031977  memory: 584  \n",
      "08/17 18:57:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [150/196]    eta: 0:00:10  time: 0.219630  data_time: 0.031762  memory: 584  \n",
      "08/17 18:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating CocoMetric...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=1.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] =  0.966\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] =  1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] =  0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] =  0.966\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] =  0.974\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] =  1.000\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] =  0.997\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] =  0.974\n",
      "08/17 18:57:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [196/196]    coco/AP: 0.966051  coco/AP .5: 1.000000  coco/AP .75: 0.990054  coco/AP (M): -1.000000  coco/AP (L): 0.966051  coco/AR: 0.974004  coco/AR .5: 1.000000  coco/AR .75: 0.996801  coco/AR (M): -1.000000  coco/AR (L): 0.974004  data_time: 0.032408  time: 0.223039\n"
     ]
    }
   ],
   "source": [
    "from src.modules.pose_estimator_2d.pose_estimator_2d import PoseEstimator2D\n",
    "\n",
    "pose_estimator_2d = PoseEstimator2D(\n",
    "    config_path='src/modules/pose_estimator_2d/config/hrnet.py',\n",
    "    # config_path='src/modules/pose_estimator_2d/config/test_config.py',\n",
    "    pretrained_path='https://download.openmmlab.com/mmpose/v1' \\\n",
    "        '/body_2d_keypoint/topdown_heatmap/coco' \\\n",
    "            '/td-hm_hrnet-w32_8xb64-210e_coco-256x192-81c58e40_20220909.pth',\n",
    "    # pretrained_path=\"mmengine_workdir/pose_estimator_2d/best_coco_AP_epoch_9.pth\",\n",
    "    # checkpoint_path=\"pose_estimator_2d_wd/best_coco_AP_epoch_0.pth\",\n",
    "    checkpoint_path=\"mmengine_workdir/pose_estimator_2d/best_coco_AP_epoch_9.pth\",\n",
    "    data_root_path='/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver',\n",
    "    device='cuda:0',\n",
    "    working_directory='mmengine_workdir/pose_estimator_2d',\n",
    "    log_level='INFO'\n",
    ")\n",
    "\n",
    "pose_estimator_2d.load_pretrained()\n",
    "# pose_estimator_2d_result = pose_estimator_2d.inference(img_path, bbox.detach().cpu().numpy(), bbox_format='xywh')\n",
    "# keypoints_2D = pose_estimator_2d_result[0].pred_instances['keypoints'][0]\n",
    "# print(keypoints_2D)\n",
    "# pose_estimator_2d.finetune()\n",
    "pose_estimator_2d.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
