{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# pose_2d\n",
                "# pose_3d"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import pickle\n",
                "import json\n",
                "import numpy as np\n",
                "\n",
                "keypoint_2d_path = ''\n",
                "keypoint_3d_path = ''\n",
                "\n",
                "synthetic_cabin_ir_1m_root_path = Path('/root/data/processed/synthetic_cabin_1m/') / 'all_views'\n",
                "drive_and_act_root_path = Path('/root/data/processed/drive_and_act/') / 'inner_mirror'\n",
                "\n",
                "# synthetic_cabin_ir_1m_keypoint_2d_path = synthetic_cabin_ir_1m_root_path / 'annotations' / 'person_keypoints_train.json'\n",
                "drive_and_act_keypoint_2d_path = drive_and_act_root_path / 'keypoint_detection_results' / 'keypoint_detection_train.json'\n",
                "# keypoint_3d_path = synthetic_cabin_ir_1m_root_path / 'annotations'\n",
                "# bbox_path = synthetic_cabin_ir_1m_root_path / 'person_detection_results'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "pose_2d = []\n",
                "pose_3d = []\n",
                "train_actors = ['vp1', 'vp2', 'vp3', 'vp4', 'vp5', 'vp6', 'vp7', 'vp8']\n",
                "# views = set(['Dashboard', 'Front', 'OMS_01'])\n",
                "# views = set(['A_Pillar_Driver', 'Front_Right', 'Front', 'TopRight'])\n",
                "viewpoints = [\n",
                "    ['Front_Left', 'Front_TopLeft', 'A_Pillar_Codriver', 'Rear_Mirror'],\n",
                "    ['Front_Right', 'Front_TopRight', 'A_Pillar_Driver'],\n",
                "    ['Dashboard', 'OMS_01', 'Front'],\n",
                "    None,\n",
                "    ['Front', 'Front_Left', 'OMS_01', 'Dashboard'],\n",
                "]\n",
                "\n",
                "views = '_'.join(viewpoints[2])\n",
                "\n",
                "# 'a_column_co_driver': 'A_Pillar_Codriver_Front_Left_Front_TopLeft_Rear_Mirror',\n",
                "# 'a_column_driver': 'A_Pillar_Driver_Front_Right_Front_TopRight',\n",
                "# 'inner_mirror': 'Dashboard_Front_OMS_01'\n",
                "synthetic_data_mapper = {}\n",
                "with open(synthetic_cabin_ir_1m_root_path / 'annotations' / 'person_keypoints_train.pkl', 'rb') as f:\n",
                "    synthetic_data = pickle.load(f)\n",
                "    for item in synthetic_data['annotations']:\n",
                "        synthetic_data_mapper[item['image_id']] = dict(\n",
                "            pose_2d=np.array(item['keypoints']).reshape(-1, 3)[:,:2],\n",
                "            pose_3d=np.array(item['keypoints3D']).reshape(-1, 3)\n",
                "        )\n",
                "\n",
                "for item in synthetic_data['images']:\n",
                "    if item['view'] in views:\n",
                "        pose_2d.append(synthetic_data_mapper[item['id']]['pose_2d'])\n",
                "        pose_3d.append(synthetic_data_mapper[item['id']]['pose_3d'])\n",
                "\n",
                "drive_and_act_kps_mapper = {}\n",
                "with open(drive_and_act_keypoint_2d_path) as f:\n",
                "    drive_and_act_kps = json.loads(f.read())\n",
                "    for item in drive_and_act_kps:\n",
                "        drive_and_act_kps_mapper[item['image_id']] = np.array(item['keypoints']).reshape(-1, 3)[:,:2]\n",
                "\n",
                "with open(drive_and_act_root_path / 'annotations' / 'person_keypoints_train.json') as f:\n",
                "    drive_and_act_anns = json.loads(f.read())\n",
                "\n",
                "for item in drive_and_act_anns['images']:\n",
                "    if item['actor'] in train_actors:\n",
                "        pose_2d.append(drive_and_act_kps_mapper[item['id']])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "synthetic_cabin_ir_1m_v2_dataset_root_path = Path('/root/data/processed/synthetic_cabin_1m/')\n",
                "keypoint_3d_path = synthetic_cabin_ir_1m_v2_dataset_root_path / 'all_views' / 'annotations'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 1234\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning.callbacks import ModelCheckpoint\n",
                "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
                "from torch.nn import functional as F\n",
                "from torch.utils.data import DataLoader, random_split\n",
                "from modules.lifter_2d_3d.dataset.gan_keypoint_dataset import GANKeypointDataset\n",
                "from modules.lifter_2d_3d.dataset.synthetic_cabin_ir_1m_dataset import SyntheticCabinIR1MKeypointDataset\n",
                "from modules.lifter_2d_3d.dataset.drive_and_act_keypoint_dataset import DriveAndActKeypointDataset\n",
                "\n",
                "from modules.lifter_2d_3d.model.linear_model.lit_linear_model import BaselineModel\n",
                "from modules.lifter_2d_3d.model.repnet.lit_repnet import LitRepNet\n",
                "from modules.utils.visualization import (\n",
                "    generate_connection_line, get_sample_from_loader, visualize_pose\n",
                ")\n",
                "from IPython.display import display\n",
                "\n",
                "pl.seed_everything(1234)\n",
                "\n",
                "train_dataset = GANKeypointDataset(\n",
                "    pose_2d,\n",
                "    pose_3d,\n",
                "    is_center_to_neck=True,\n",
                "    is_normalize_to_bbox=False,\n",
                "    is_normalize_to_pose=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train_dataset 175001 val_dataset 87500 test_dataset 10959\n"
                    ]
                }
            ],
            "source": [
                "val_dataset = SyntheticCabinIR1MKeypointDataset(\n",
                "    prediction_file=(synthetic_cabin_ir_1m_root_path / 'annotations' / 'person_keypoints_val.json').as_posix(),\n",
                "    annotation_file=(synthetic_cabin_ir_1m_root_path / 'annotations' / 'person_keypoints_val.json').as_posix(),\n",
                "    bbox_file=(synthetic_cabin_ir_1m_root_path / 'person_detection_results' / f'ground_truth_human_detection_val.json').as_posix(),\n",
                "    image_width=1280,\n",
                "    image_height=1024,\n",
                "    exclude_ankle=True,\n",
                "    exclude_knee=True,\n",
                "    bbox_format='xyxy',\n",
                "    is_center_to_neck=True,\n",
                "    is_normalize_to_bbox=False,\n",
                "    is_normalize_to_pose=True,\n",
                "    # is_normalize_rotation=True,\n",
                "    is_gt_2d_pose=True,\n",
                "    included_view='Dashboard_Front_OMS_01',\n",
                "    subset_percentage=100\n",
                ")\n",
                "test_dataset = DriveAndActKeypointDataset(\n",
                "    prediction_file=(drive_and_act_root_path / 'keypoint_detection_results' / 'keypoint_detection_train.json').as_posix(),\n",
                "    annotation_file=(drive_and_act_root_path / 'annotations' / 'person_keypoints_train.json').as_posix(),\n",
                "    bbox_file=(drive_and_act_root_path / 'person_detection_results' / 'human_detection_train.json').as_posix(),\n",
                "    image_width=1280,\n",
                "    image_height=1024,\n",
                "    actors=['vp11', 'vp12', 'vp13', 'vp14'],\n",
                "    exclude_ankle=True,\n",
                "    exclude_knee=True,\n",
                "    bbox_format='xyxy',\n",
                "    is_center_to_neck=True,\n",
                "    is_normalize_to_bbox=False,\n",
                "    is_normalize_to_pose=True,\n",
                "    # is_normalize_rotation=True\n",
                ")\n",
                "all_activities = test_dataset.activities\n",
                "print(\n",
                "    'train_dataset', len(train_dataset),\n",
                "    'val_dataset', len(val_dataset),\n",
                "    'test_dataset', len(test_dataset)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DataModule(pl.LightningDataModule):\n",
                "    def __init__(self, train_dataset, val_dataset, test_dataset):\n",
                "        super().__init__()\n",
                "        self.train_dataset = train_dataset\n",
                "        self.val_dataset = val_dataset\n",
                "        self.test_dataset = test_dataset\n",
                "\n",
                "    def train_dataloader(self):\n",
                "        self.train_dataset.shuffle()\n",
                "        return DataLoader(self.train_dataset, batch_size=64, drop_last=True, shuffle=True, num_workers=24)\n",
                "\n",
                "    def val_dataloader(self):\n",
                "        return DataLoader(self.val_dataset, batch_size=64, drop_last=True, num_workers=24)\n",
                "\n",
                "    def test_dataloader(self):\n",
                "        return DataLoader(test_dataset, batch_size=64, num_workers=24)\n",
                "dm = DataModule(train_dataset, val_dataset, test_dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "device cuda\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name          | Type               | Params\n",
                        "-----------------------------------------------------\n",
                        "0 | lifter_2D_3D  | BaselineModel      | 4.3 M \n",
                        "1 | camera_net    | CameraNet          | 4.0 M \n",
                        "2 | generator     | RepNet             | 8.3 M \n",
                        "3 | discriminator | DiscriminatorModel | 89.2 K\n",
                        "-----------------------------------------------------\n",
                        "8.4 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "8.4 M     Total params\n",
                        "33.650    Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "abeeb8b35ad04fa5bdbe848e6e7aee78",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Sanity Checking: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #0\n",
                        "val MPJPE from: 128 samples : 2413.00106048584\n",
                        "val P-MPJPE from: 128 samples : 2257.245683200801\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a2f6e42e38b245c3b1912a77f420c853",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f26b577e721d4631a03b5ca503eee54c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #1\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 4.000194306476498\n",
                        "g_loss = -0.3171215193630922\n",
                        "c_loss = 1.6964033265661478\n",
                        "pose_2d_loss = 19.026358204290826\n",
                        "total_g_loss = 20.405640016704382\n",
                        "val MPJPE from: 87488 samples : 583.5568904876709\n",
                        "val P-MPJPE from: 87488 samples : 507.3185247359221\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a3ee5af8b4bf47d99e96abc578332a68",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #2\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 2.646818237140742\n",
                        "g_loss = -0.48108430491282106\n",
                        "c_loss = 1.4266565992676086\n",
                        "pose_2d_loss = 0.6958456196506789\n",
                        "total_g_loss = 1.641417915520654\n",
                        "val MPJPE from: 87488 samples : 268.95180344581604\n",
                        "val P-MPJPE from: 87488 samples : 193.12810890197687\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2277c830f06b439bad995dc71305dced",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #3\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 1.9838134422217004\n",
                        "g_loss = -0.2322868193074638\n",
                        "c_loss = 0.1469886516341456\n",
                        "pose_2d_loss = 0.15307715130477992\n",
                        "total_g_loss = 0.06777898385717473\n",
                        "val MPJPE from: 87488 samples : 225.6813496351242\n",
                        "val P-MPJPE from: 87488 samples : 143.78792766604963\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "48c888cd5e6543838ac766280e73ced0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #4\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 2.9293872515576256\n",
                        "g_loss = -0.6580980637689184\n",
                        "c_loss = 0.07969440921838583\n",
                        "pose_2d_loss = 0.13484089864838947\n",
                        "total_g_loss = -0.44356275564597836\n",
                        "val MPJPE from: 87488 samples : 666.2312150001526\n",
                        "val P-MPJPE from: 87488 samples : 498.104759432239\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a2160df446d8445eadba5133a091215b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #5\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.7412513962680448\n",
                        "g_loss = -0.783422088919544\n",
                        "c_loss = 0.10468553785158385\n",
                        "pose_2d_loss = 0.16572224428903123\n",
                        "total_g_loss = -0.513014307821983\n",
                        "val MPJPE from: 87488 samples : 195.63935697078705\n",
                        "val P-MPJPE from: 87488 samples : 140.43709919044215\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b91762ce660b4d6a8fb2f2491daae7f7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #6\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.23228886132057\n",
                        "g_loss = -0.2645832579351291\n",
                        "c_loss = 0.05056089875455223\n",
                        "pose_2d_loss = 0.09627512287302181\n",
                        "total_g_loss = -0.11774723623125066\n",
                        "val MPJPE from: 87488 samples : 219.93203461170197\n",
                        "val P-MPJPE from: 87488 samples : 152.15893118546617\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e12068cb16754f03b872b380e93cc216",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #7\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.21779380092464098\n",
                        "g_loss = -0.20204246184027644\n",
                        "c_loss = 0.03560646896876651\n",
                        "pose_2d_loss = 0.08142674722229815\n",
                        "total_g_loss = -0.0850092456638595\n",
                        "val MPJPE from: 87488 samples : 263.0278468132019\n",
                        "val P-MPJPE from: 87488 samples : 187.83755025585404\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cf01e3d450de45a792ae03131199b0ee",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #8\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.10193146333601204\n",
                        "g_loss = -0.2083491168632809\n",
                        "c_loss = 0.029649483672211707\n",
                        "pose_2d_loss = 0.08568365601570657\n",
                        "total_g_loss = -0.09301597704591764\n",
                        "val MPJPE from: 87488 samples : 204.80580627918243\n",
                        "val P-MPJPE from: 87488 samples : 135.51368907818556\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "08b0c3ae40414dbfb1a3ccd197b3d9c9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #9\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.023585450488409054\n",
                        "g_loss = -0.35369488203403454\n",
                        "c_loss = 0.026001678884639823\n",
                        "pose_2d_loss = 0.09054300838695797\n",
                        "total_g_loss = -0.2371501944790204\n",
                        "val MPJPE from: 87488 samples : 190.32154977321625\n",
                        "val P-MPJPE from: 87488 samples : 130.89642623345438\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6acdaa5694ef495bb92def47167c3073",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #10\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.015559512074275764\n",
                        "g_loss = -0.42226782635170435\n",
                        "c_loss = 0.02471188518192126\n",
                        "pose_2d_loss = 0.09243330615351213\n",
                        "total_g_loss = -0.30512263505408255\n",
                        "val MPJPE from: 87488 samples : 197.6698935031891\n",
                        "val P-MPJPE from: 87488 samples : 137.2220749325854\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2acea742c29d4b3bb8eea3ef17e22d80",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #11\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.009019613534589547\n",
                        "g_loss = -0.45299105681942253\n",
                        "c_loss = 0.022002744558590907\n",
                        "pose_2d_loss = 0.0914857044554402\n",
                        "total_g_loss = -0.3395026083640487\n",
                        "val MPJPE from: 87488 samples : 197.31631875038147\n",
                        "val P-MPJPE from: 87488 samples : 135.0627359206284\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e42f403dd242470e8a82abf714b417eb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #12\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.004676292971033404\n",
                        "g_loss = -0.46188073115315675\n",
                        "c_loss = 0.019335597779073132\n",
                        "pose_2d_loss = 0.0907661622552298\n",
                        "total_g_loss = -0.35177897092911475\n",
                        "val MPJPE from: 87488 samples : 195.1470822095871\n",
                        "val P-MPJPE from: 87488 samples : 134.3221557336994\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "51fdbe0372564ad8979ed2d0ba874372",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #13\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.2252886310197112\n",
                        "g_loss = -0.3043950639185499\n",
                        "c_loss = 0.018619375691041294\n",
                        "pose_2d_loss = 0.088377516670391\n",
                        "total_g_loss = -0.19739817134523663\n",
                        "val MPJPE from: 87488 samples : 1495.0006008148193\n",
                        "val P-MPJPE from: 87488 samples : 1109.4637988366237\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dcb1089a9c604c25a3162b804e645ba5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #14\n",
                        "training loss from 2734 batches:\n",
                        "d_loss = 0.17318714065129795\n",
                        "g_loss = -0.2931862027188811\n",
                        "c_loss = 0.024115689053188602\n",
                        "pose_2d_loss = 0.10593464032316958\n",
                        "total_g_loss = -0.16313587314154251\n",
                        "val MPJPE from: 87488 samples : 190.39294123649597\n",
                        "val P-MPJPE from: 87488 samples : 135.89011717565833\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# train_loader = DataLoader(train_dataset, batch_size=64, drop_last=True, shuffle=True, num_workers=24)\n",
                "# val_loader = DataLoader(val_dataset, batch_size=64, drop_last=True, num_workers=24)\n",
                "# test_loader = DataLoader(test_dataset, batch_size=64, num_workers=24)\n",
                "\n",
                "model_checkpoint = ModelCheckpoint(monitor='mpjpe',mode='min', save_top_k=1)\n",
                "early_stopping = EarlyStopping(monitor='mpjpe', mode=\"min\", patience=5)\n",
                "\n",
                "# ------------\n",
                "# model\n",
                "# ------------\n",
                "lifter_2D_3D = BaselineModel(exclude_ankle=True, exclude_knee=True)\n",
                "lit_model = LitRepNet(\n",
                "    lifter_2D_3D=lifter_2D_3D,\n",
                "    all_activities=all_activities,\n",
                ")\n",
                "# ------------\n",
                "# training\n",
                "# ------------\n",
                "saved_model_path = './saved_lifter_2d_3d_model/rq3/repnet'\n",
                "if not os.path.exists(saved_model_path):\n",
                "    os.makedirs(saved_model_path)\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print('device', device)\n",
                "# device = 'cpu'\n",
                "trainer = pl.Trainer(\n",
                "    # max_steps=10,\n",
                "    max_epochs=100,\n",
                "    callbacks=[model_checkpoint, early_stopping],\n",
                "    accelerator=device,\n",
                "    check_val_every_n_epoch=1,\n",
                "    default_root_dir=saved_model_path,\n",
                "    # gradient_clip_val=1.0\n",
                "    reload_dataloaders_every_n_epochs=1,\n",
                "    log_every_n_steps=1\n",
                ")\n",
                "# trainer.fit(lit_model, train_loader, val_loader)\n",
                "trainer.fit(lit_model, dm)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Restoring states from the checkpoint path at saved_lifter_2d_3d_model/rq3/repnet/lightning_logs/version_3/checkpoints/epoch=8-step=49212.ckpt\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "Loaded model weights from the checkpoint at saved_lifter_2d_3d_model/rq3/repnet/lightning_logs/version_3/checkpoints/epoch=8-step=49212.ckpt\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cd07459067a647f8b7ec8b0f3fcf284e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Testing: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">   activity_macro_mpjpe    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    177.86507308483124     </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">           mpjpe           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    164.70582783222198     </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">  p_activity_macro_mpjpe   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     127.4467489217613     </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">          p_mpjpe          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    106.36243001577783     </span>│\n",
                            "└───────────────────────────┴───────────────────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│\u001b[36m \u001b[0m\u001b[36m  activity_macro_mpjpe   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   177.86507308483124    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m          mpjpe          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   164.70582783222198    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m p_activity_macro_mpjpe  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    127.4467489217613    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m         p_mpjpe         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   106.36243001577783    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "└───────────────────────────┴───────────────────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "[{'mpjpe': 164.70582783222198,\n",
                            "  'p_mpjpe': 106.36243001577783,\n",
                            "  'activity_macro_mpjpe': 177.86507308483124,\n",
                            "  'p_activity_macro_mpjpe': 127.4467489217613}]"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "best_checkpoint_path = model_checkpoint.best_model_path\n",
                "trainer.test(ckpt_path=best_checkpoint_path, datamodule=dm)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
