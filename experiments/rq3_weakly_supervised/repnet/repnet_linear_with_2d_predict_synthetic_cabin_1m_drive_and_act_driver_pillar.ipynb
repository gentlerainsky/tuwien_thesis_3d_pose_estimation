{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# pose_2d\n",
                "# pose_3d"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import pickle\n",
                "import json\n",
                "import numpy as np\n",
                "\n",
                "keypoint_2d_path = ''\n",
                "keypoint_3d_path = ''\n",
                "viewpoint_idx = 1\n",
                "synthetic_cabin_ir_1m_root_path = Path('/root/data/processed/synthetic_cabin_1m/') / 'all_views'\n",
                "drive_and_act_views = ['a_column_co_driver', 'a_column_driver', 'inner_mirror']\n",
                "drive_and_act_root_path = Path('/root/data/processed/drive_and_act/') / drive_and_act_views[viewpoint_idx]\n",
                "\n",
                "# synthetic_cabin_ir_1m_keypoint_2d_path = synthetic_cabin_ir_1m_root_path / 'annotations' / 'person_keypoints_train.json'\n",
                "drive_and_act_keypoint_2d_path = drive_and_act_root_path / 'keypoint_detection_results' / 'keypoint_detection_train.json'\n",
                "# keypoint_3d_path = synthetic_cabin_ir_1m_root_path / 'annotations'\n",
                "# bbox_path = synthetic_cabin_ir_1m_root_path / 'person_detection_results'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "pose_2d = []\n",
                "pose_3d = []\n",
                "train_actors = ['vp1', 'vp2', 'vp3', 'vp4', 'vp5', 'vp6', 'vp7', 'vp8']\n",
                "# views = set(['Dashboard', 'Front', 'OMS_01'])\n",
                "# views = set(['A_Pillar_Driver', 'Front_Right', 'Front', 'TopRight'])\n",
                "viewpoints = [\n",
                "    ['Front_Left', 'Front_TopLeft', 'A_Pillar_Codriver', 'Rear_Mirror'],\n",
                "    ['Front_Right', 'Front_TopRight', 'A_Pillar_Driver'],\n",
                "    ['Dashboard', 'OMS_01', 'Front'],\n",
                "    None,\n",
                "    ['Front', 'Front_Left', 'OMS_01', 'Dashboard'],\n",
                "]\n",
                "\n",
                "views = viewpoints[viewpoint_idx]\n",
                "view_name = '_'.join(sorted(views))\n",
                "# 'a_column_co_driver': 'A_Pillar_Codriver_Front_Left_Front_TopLeft_Rear_Mirror',\n",
                "# 'a_column_driver': 'A_Pillar_Driver_Front_Right_Front_TopRight',\n",
                "# 'inner_mirror': 'Dashboard_Front_OMS_01'\n",
                "synthetic_data_mapper = {}\n",
                "with open(synthetic_cabin_ir_1m_root_path / 'annotations' / 'person_keypoints_train.pkl', 'rb') as f:\n",
                "    synthetic_data = pickle.load(f)\n",
                "    for item in synthetic_data['annotations']:\n",
                "        synthetic_data_mapper[item['image_id']] = dict(\n",
                "            pose_2d=np.array(item['keypoints']).reshape(-1, 3)[:,:2],\n",
                "            pose_3d=np.array(item['keypoints3D']).reshape(-1, 3)\n",
                "        )\n",
                "\n",
                "for item in synthetic_data['images']:\n",
                "    if item['view'] in views:\n",
                "        pose_2d.append(synthetic_data_mapper[item['id']]['pose_2d'])\n",
                "        pose_3d.append(synthetic_data_mapper[item['id']]['pose_3d'])\n",
                "\n",
                "drive_and_act_kps_mapper = {}\n",
                "with open(drive_and_act_keypoint_2d_path) as f:\n",
                "    drive_and_act_kps = json.loads(f.read())\n",
                "    for item in drive_and_act_kps:\n",
                "        drive_and_act_kps_mapper[item['image_id']] = np.array(item['keypoints']).reshape(-1, 3)[:,:2]\n",
                "\n",
                "with open(drive_and_act_root_path / 'annotations' / 'person_keypoints_train.json') as f:\n",
                "    drive_and_act_anns = json.loads(f.read())\n",
                "\n",
                "for item in drive_and_act_anns['images']:\n",
                "    if item['actor'] in train_actors:\n",
                "        if item['id'] in drive_and_act_kps_mapper:\n",
                "            pose_2d.append(drive_and_act_kps_mapper[item['id']])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "synthetic_cabin_ir_1m_v2_dataset_root_path = Path('/root/data/processed/synthetic_cabin_1m/')\n",
                "keypoint_3d_path = synthetic_cabin_ir_1m_v2_dataset_root_path / 'all_views' / 'annotations'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Global seed set to 1234\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning.callbacks import ModelCheckpoint\n",
                "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
                "from torch.nn import functional as F\n",
                "from torch.utils.data import DataLoader, random_split\n",
                "from modules.lifter_2d_3d.dataset.gan_keypoint_dataset import GANKeypointDataset\n",
                "from modules.lifter_2d_3d.dataset.synthetic_cabin_ir_1m_dataset import SyntheticCabinIR1MKeypointDataset\n",
                "from modules.lifter_2d_3d.dataset.drive_and_act_keypoint_dataset import DriveAndActKeypointDataset\n",
                "\n",
                "from modules.lifter_2d_3d.model.linear_model.lit_linear_model import BaselineModel\n",
                "from modules.lifter_2d_3d.model.repnet.lit_repnet import LitRepNet\n",
                "from modules.utils.visualization import (\n",
                "    generate_connection_line, get_sample_from_loader, visualize_pose\n",
                ")\n",
                "from IPython.display import display\n",
                "\n",
                "pl.seed_everything(1234)\n",
                "\n",
                "train_dataset = GANKeypointDataset(\n",
                "    pose_2d,\n",
                "    pose_3d,\n",
                "    is_center_to_neck=True,\n",
                "    is_normalize_to_bbox=False,\n",
                "    is_normalize_to_pose=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train_dataset 125000 val_dataset 62500 test_dataset 10959\n"
                    ]
                }
            ],
            "source": [
                "val_dataset = SyntheticCabinIR1MKeypointDataset(\n",
                "    prediction_file=(synthetic_cabin_ir_1m_root_path / 'annotations' / 'person_keypoints_val.json').as_posix(),\n",
                "    annotation_file=(synthetic_cabin_ir_1m_root_path / 'annotations' / 'person_keypoints_val.json').as_posix(),\n",
                "    bbox_file=(synthetic_cabin_ir_1m_root_path / 'person_detection_results' / f'ground_truth_human_detection_val.json').as_posix(),\n",
                "    image_width=1280,\n",
                "    image_height=1024,\n",
                "    exclude_ankle=True,\n",
                "    exclude_knee=True,\n",
                "    bbox_format='xyxy',\n",
                "    is_center_to_neck=True,\n",
                "    is_normalize_to_bbox=False,\n",
                "    is_normalize_to_pose=True,\n",
                "    # is_normalize_rotation=True,\n",
                "    is_gt_2d_pose=True,\n",
                "    included_view=views,\n",
                "    subset_percentage=100\n",
                ")\n",
                "test_dataset = DriveAndActKeypointDataset(\n",
                "    prediction_file=(drive_and_act_root_path / 'keypoint_detection_results' / 'keypoint_detection_train.json').as_posix(),\n",
                "    annotation_file=(drive_and_act_root_path / 'annotations' / 'person_keypoints_train.json').as_posix(),\n",
                "    bbox_file=(drive_and_act_root_path / 'person_detection_results' / 'human_detection_train.json').as_posix(),\n",
                "    image_width=1280,\n",
                "    image_height=1024,\n",
                "    actors=['vp11', 'vp12', 'vp13', 'vp14'],\n",
                "    exclude_ankle=True,\n",
                "    exclude_knee=True,\n",
                "    bbox_format='xyxy',\n",
                "    is_center_to_neck=True,\n",
                "    is_normalize_to_bbox=False,\n",
                "    is_normalize_to_pose=True,\n",
                "    # is_normalize_rotation=True\n",
                ")\n",
                "all_activities = test_dataset.activities\n",
                "print(\n",
                "    'train_dataset', len(train_dataset),\n",
                "    'val_dataset', len(val_dataset),\n",
                "    'test_dataset', len(test_dataset)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DataModule(pl.LightningDataModule):\n",
                "    def __init__(self, train_dataset, val_dataset, test_dataset):\n",
                "        super().__init__()\n",
                "        self.train_dataset = train_dataset\n",
                "        self.val_dataset = val_dataset\n",
                "        self.test_dataset = test_dataset\n",
                "\n",
                "    def train_dataloader(self):\n",
                "        self.train_dataset.shuffle()\n",
                "        return DataLoader(self.train_dataset, batch_size=64, drop_last=True, shuffle=True, num_workers=24)\n",
                "\n",
                "    def val_dataloader(self):\n",
                "        return DataLoader(self.val_dataset, batch_size=64, drop_last=True, num_workers=24)\n",
                "\n",
                "    def test_dataloader(self):\n",
                "        return DataLoader(test_dataset, batch_size=64, num_workers=24)\n",
                "dm = DataModule(train_dataset, val_dataset, test_dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "device cuda\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name          | Type               | Params\n",
                        "-----------------------------------------------------\n",
                        "0 | lifter_2D_3D  | BaselineModel      | 4.3 M \n",
                        "1 | camera_net    | CameraNet          | 4.0 M \n",
                        "2 | generator     | RepNet             | 8.3 M \n",
                        "3 | discriminator | DiscriminatorModel | 89.2 K\n",
                        "-----------------------------------------------------\n",
                        "8.4 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "8.4 M     Total params\n",
                        "33.650    Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2ec86bd6422241f3858cd44318a287ec",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Sanity Checking: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #0\n",
                        "val MPJPE from: 128 samples : 2342.7369594573975\n",
                        "val P-MPJPE from: 128 samples : 2189.4767198425075\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3ed38d3164aa49e7b62811f151d5f54e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "48102c10d031450382c4c951f34ba5fd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #1\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 3.985507103338403\n",
                        "g_loss = -0.27661477044583344\n",
                        "c_loss = 1.6952360658479604\n",
                        "pose_2d_loss = 21.46005831934279\n",
                        "total_g_loss = 22.878679626121073\n",
                        "val MPJPE from: 62464 samples : 510.2905035018921\n",
                        "val P-MPJPE from: 62464 samples : 396.8697757853684\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c6b890ea932142179ef6523d017ca5ef",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #2\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 3.0675375420071807\n",
                        "g_loss = -0.2948867012248305\n",
                        "c_loss = 1.696363891202611\n",
                        "pose_2d_loss = 1.237800030725404\n",
                        "total_g_loss = 2.6392772167203855\n",
                        "val MPJPE from: 62464 samples : 393.5927748680115\n",
                        "val P-MPJPE from: 62464 samples : 299.9650555106294\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "feaa389654304397aac73d225f7d376e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #3\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 5.766446107757195\n",
                        "g_loss = -0.5234622515211549\n",
                        "c_loss = 0.7678103607950977\n",
                        "pose_2d_loss = 0.4770758644440695\n",
                        "total_g_loss = 0.7214239721443491\n",
                        "val MPJPE from: 62464 samples : 353.2557487487793\n",
                        "val P-MPJPE from: 62464 samples : 286.2947673510532\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "27c82685d4174ca8bd37a5942db043d8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #4\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 7.587106237999611\n",
                        "g_loss = -0.7933859027658923\n",
                        "c_loss = 0.09477574096041738\n",
                        "pose_2d_loss = 0.10714095579703466\n",
                        "total_g_loss = -0.5914692054772096\n",
                        "val MPJPE from: 62464 samples : 375.97140669822693\n",
                        "val P-MPJPE from: 62464 samples : 268.7540032820038\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0022bd72e2a145b9b58649e2e1f9556e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #5\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 4.333091296236514\n",
                        "g_loss = -0.8141501553726697\n",
                        "c_loss = 0.05271088082583681\n",
                        "pose_2d_loss = 0.20492013984231525\n",
                        "total_g_loss = -0.5565191349019408\n",
                        "val MPJPE from: 62464 samples : 188.78977000713348\n",
                        "val P-MPJPE from: 62464 samples : 121.90026924603055\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4dbbe2e0e96146d1a3d3fc684b0a4add",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #6\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 0.33119918507487117\n",
                        "g_loss = -0.4956655337323119\n",
                        "c_loss = 0.07355767573552809\n",
                        "pose_2d_loss = 0.14843692107882428\n",
                        "total_g_loss = -0.27367093627323447\n",
                        "val MPJPE from: 62464 samples : 302.42034792900085\n",
                        "val P-MPJPE from: 62464 samples : 220.07248751747602\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0c1e0ed4987d4a38a62575dbe7ee5274",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #7\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 0.2275008742477701\n",
                        "g_loss = -0.3654157374830534\n",
                        "c_loss = 0.07484577813734626\n",
                        "pose_2d_loss = 0.15283145857769834\n",
                        "total_g_loss = -0.13773850067740395\n",
                        "val MPJPE from: 62464 samples : 182.20078945159912\n",
                        "val P-MPJPE from: 62464 samples : 130.7664123555565\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "05ee2774652349b28278ac09928bee14",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #8\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 0.3390498112293921\n",
                        "g_loss = -0.17998615284562416\n",
                        "c_loss = 0.0381711909411064\n",
                        "pose_2d_loss = 0.09823062093866464\n",
                        "total_g_loss = -0.04358434103166087\n",
                        "val MPJPE from: 62464 samples : 199.67179000377655\n",
                        "val P-MPJPE from: 62464 samples : 129.84275398453502\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3776894e1b944468b10bad137f57071e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #9\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 0.4195115970580229\n",
                        "g_loss = -0.2642977972001341\n",
                        "c_loss = 0.032855488766219396\n",
                        "pose_2d_loss = 0.10083726025675269\n",
                        "total_g_loss = -0.13060504837458523\n",
                        "val MPJPE from: 62464 samples : 430.0924837589264\n",
                        "val P-MPJPE from: 62464 samples : 388.7584454442843\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8188035fbc9143219fe000bade743e42",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #10\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 0.5429928530278462\n",
                        "g_loss = -0.7783652955730085\n",
                        "c_loss = 0.03292336591833671\n",
                        "pose_2d_loss = 0.08954106252144543\n",
                        "total_g_loss = -0.6559008676396598\n",
                        "val MPJPE from: 62464 samples : 207.16160535812378\n",
                        "val P-MPJPE from: 62464 samples : 136.60371188738557\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a9ed70dbadd844f6836fd44cd7ef6270",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #11\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 0.17352165929597355\n",
                        "g_loss = -0.31585634941939994\n",
                        "c_loss = 0.027524625785225364\n",
                        "pose_2d_loss = 0.10265849689779927\n",
                        "total_g_loss = -0.18567322666866012\n",
                        "val MPJPE from: 62464 samples : 209.10583436489105\n",
                        "val P-MPJPE from: 62464 samples : 143.81021852867244\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5a4daa8ed11f46919b64b8277d5f285d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "check #12\n",
                        "training loss from 1953 batches:\n",
                        "d_loss = 0.12008395920475659\n",
                        "g_loss = -0.2551837022556016\n",
                        "c_loss = 0.02812352515346978\n",
                        "pose_2d_loss = 0.1010264526428898\n",
                        "total_g_loss = -0.1260337244225232\n",
                        "val MPJPE from: 62464 samples : 200.4631906747818\n",
                        "val P-MPJPE from: 62464 samples : 137.57903674102582\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# train_loader = DataLoader(train_dataset, batch_size=64, drop_last=True, shuffle=True, num_workers=24)\n",
                "# val_loader = DataLoader(val_dataset, batch_size=64, drop_last=True, num_workers=24)\n",
                "# test_loader = DataLoader(test_dataset, batch_size=64, num_workers=24)\n",
                "\n",
                "model_checkpoint = ModelCheckpoint(monitor='mpjpe',mode='min', save_top_k=1)\n",
                "early_stopping = EarlyStopping(monitor='mpjpe', mode=\"min\", patience=5)\n",
                "\n",
                "# ------------\n",
                "# model\n",
                "# ------------\n",
                "lifter_2D_3D = BaselineModel(exclude_ankle=True, exclude_knee=True)\n",
                "lit_model = LitRepNet(\n",
                "    lifter_2D_3D=lifter_2D_3D,\n",
                "    all_activities=all_activities,\n",
                ")\n",
                "# ------------\n",
                "# training\n",
                "# ------------\n",
                "saved_model_path = './saved_lifter_2d_3d_model/rq3/repnet/synthetic_and_real/co_driver_pillar'\n",
                "if not os.path.exists(saved_model_path):\n",
                "    os.makedirs(saved_model_path)\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print('device', device)\n",
                "# device = 'cpu'\n",
                "trainer = pl.Trainer(\n",
                "    # max_steps=10,\n",
                "    max_epochs=100,\n",
                "    callbacks=[model_checkpoint, early_stopping],\n",
                "    accelerator=device,\n",
                "    check_val_every_n_epoch=1,\n",
                "    default_root_dir=saved_model_path,\n",
                "    # gradient_clip_val=1.0\n",
                "    reload_dataloaders_every_n_epochs=1,\n",
                "    log_every_n_steps=1\n",
                ")\n",
                "# trainer.fit(lit_model, train_loader, val_loader)\n",
                "trainer.fit(lit_model, dm)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Restoring states from the checkpoint path at saved_lifter_2d_3d_model/rq3/repnet/synthetic_and_real/co_driver_pillar/lightning_logs/version_1/checkpoints/epoch=6-step=27342.ckpt\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "Loaded model weights from the checkpoint at saved_lifter_2d_3d_model/rq3/repnet/synthetic_and_real/co_driver_pillar/lightning_logs/version_1/checkpoints/epoch=6-step=27342.ckpt\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1f31517f2b96446b8030e8c2f9787320",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Testing: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">   activity_macro_mpjpe    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     257.7551603317261     </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">           mpjpe           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    247.72658944129944     </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">  p_activity_macro_mpjpe   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    144.90475432319326     </span>│\n",
                            "│<span style=\"color: #008080; text-decoration-color: #008080\">          p_mpjpe          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    130.28864511497096     </span>│\n",
                            "└───────────────────────────┴───────────────────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
                            "│\u001b[36m \u001b[0m\u001b[36m  activity_macro_mpjpe   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    257.7551603317261    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m          mpjpe          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   247.72658944129944    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m p_activity_macro_mpjpe  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   144.90475432319326    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "│\u001b[36m \u001b[0m\u001b[36m         p_mpjpe         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   130.28864511497096    \u001b[0m\u001b[35m \u001b[0m│\n",
                            "└───────────────────────────┴───────────────────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "[{'mpjpe': 247.72658944129944,\n",
                            "  'p_mpjpe': 130.28864511497096,\n",
                            "  'activity_macro_mpjpe': 257.7551603317261,\n",
                            "  'p_activity_macro_mpjpe': 144.90475432319326}]"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "best_checkpoint_path = model_checkpoint.best_model_path\n",
                "trainer.test(ckpt_path=best_checkpoint_path, datamodule=dm)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
