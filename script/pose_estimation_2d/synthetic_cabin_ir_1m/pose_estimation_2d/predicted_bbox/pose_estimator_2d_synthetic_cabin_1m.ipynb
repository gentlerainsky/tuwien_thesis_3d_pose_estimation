{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 18:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 116775334\n",
      "    GPU 0: NVIDIA TITAN Xp\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.99\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 2.0.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.8.2\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 116775334\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "11/18 18:24:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "default_scope = 'mmpose'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook', _scope_='mmpose'),\n",
      "    logger=dict(type='LoggerHook', interval=50, _scope_='mmpose'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook', _scope_='mmpose'),\n",
      "    checkpoint=dict(\n",
      "        type='CheckpointHook',\n",
      "        interval=10,\n",
      "        save_best='coco/AP',\n",
      "        rule='greater',\n",
      "        _scope_='mmpose'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook', _scope_='mmpose'),\n",
      "    visualization=dict(\n",
      "        type='PoseVisualizationHook', enable=False, _scope_='mmpose'))\n",
      "custom_hooks = [\n",
      "    dict(type='SyncBuffersHook', _scope_='mmpose'),\n",
      "]\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend', _scope_='mmpose'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='PoseLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "        dict(type='WandbVisBackend'),\n",
      "    ],\n",
      "    name='visualizer',\n",
      "    _scope_='mmpose')\n",
      "log_processor = dict(\n",
      "    type='LogProcessor',\n",
      "    window_size=50,\n",
      "    by_epoch=True,\n",
      "    num_digits=6,\n",
      "    _scope_='mmpose')\n",
      "log_level = 'INFO'\n",
      "load_from = 'https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288-70d7ab01_20220913.pth'\n",
      "resume = False\n",
      "backend_args = dict(backend='local')\n",
      "train_cfg = dict(by_epoch=True, max_epochs=10, val_interval=1)\n",
      "val_cfg = dict()\n",
      "test_cfg = dict()\n",
      "optim_wrapper = dict(optimizer=dict(type='Adam', lr=0.0005, _scope_='mmpose'))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='LinearLR',\n",
      "        begin=0,\n",
      "        end=500,\n",
      "        start_factor=0.001,\n",
      "        by_epoch=False,\n",
      "        _scope_='mmpose'),\n",
      "    dict(\n",
      "        type='MultiStepLR',\n",
      "        begin=0,\n",
      "        end=210,\n",
      "        milestones=[\n",
      "            170,\n",
      "            200,\n",
      "        ],\n",
      "        gamma=0.1,\n",
      "        by_epoch=True,\n",
      "        _scope_='mmpose'),\n",
      "]\n",
      "auto_scale_lr = dict(base_batch_size=512)\n",
      "codec = dict(\n",
      "    type='UDPHeatmap',\n",
      "    input_size=(\n",
      "        288,\n",
      "        384,\n",
      "    ),\n",
      "    heatmap_size=(\n",
      "        72,\n",
      "        96,\n",
      "    ),\n",
      "    sigma=3,\n",
      "    _scope_='mmpose')\n",
      "model = dict(\n",
      "    type='TopdownPoseEstimator',\n",
      "    data_preprocessor=dict(\n",
      "        type='PoseDataPreprocessor',\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        bgr_to_rgb=True),\n",
      "    backbone=dict(\n",
      "        type='HRNet',\n",
      "        in_channels=3,\n",
      "        extra=dict(\n",
      "            stage1=dict(\n",
      "                num_modules=1,\n",
      "                num_branches=1,\n",
      "                block='BOTTLENECK',\n",
      "                num_blocks=(4, ),\n",
      "                num_channels=(64, )),\n",
      "            stage2=dict(\n",
      "                num_modules=1,\n",
      "                num_branches=2,\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_channels=(\n",
      "                    48,\n",
      "                    96,\n",
      "                )),\n",
      "            stage3=dict(\n",
      "                num_modules=4,\n",
      "                num_branches=3,\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_channels=(\n",
      "                    48,\n",
      "                    96,\n",
      "                    192,\n",
      "                )),\n",
      "            stage4=dict(\n",
      "                num_modules=3,\n",
      "                num_branches=4,\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_channels=(\n",
      "                    48,\n",
      "                    96,\n",
      "                    192,\n",
      "                    384,\n",
      "                ))),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmpose/pretrain_models/hrnet_w48-8ef0771d.pth'\n",
      "        )),\n",
      "    head=dict(\n",
      "        type='HeatmapHead',\n",
      "        in_channels=48,\n",
      "        out_channels=17,\n",
      "        deconv_out_channels=None,\n",
      "        loss=dict(type='KeypointMSELoss', use_target_weight=True),\n",
      "        decoder=dict(\n",
      "            type='UDPHeatmap',\n",
      "            input_size=(\n",
      "                288,\n",
      "                384,\n",
      "            ),\n",
      "            heatmap_size=(\n",
      "                72,\n",
      "                96,\n",
      "            ),\n",
      "            sigma=3)),\n",
      "    test_cfg=dict(flip_test=True, flip_mode='heatmap', shift_heatmap=False),\n",
      "    _scope_='mmpose')\n",
      "dataset_type = 'CocoDataset'\n",
      "data_mode = 'topdown'\n",
      "data_root = '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/'\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImage', _scope_='mmpose'),\n",
      "    dict(type='GetBBoxCenterScale', _scope_='mmpose'),\n",
      "    dict(type='RandomFlip', direction='horizontal', _scope_='mmpose'),\n",
      "    dict(type='RandomHalfBody', _scope_='mmpose'),\n",
      "    dict(type='RandomBBoxTransform', _scope_='mmpose'),\n",
      "    dict(\n",
      "        type='TopdownAffine',\n",
      "        input_size=(\n",
      "            288,\n",
      "            384,\n",
      "        ),\n",
      "        use_udp=True,\n",
      "        _scope_='mmpose'),\n",
      "    dict(\n",
      "        type='GenerateTarget',\n",
      "        encoder=dict(\n",
      "            type='UDPHeatmap',\n",
      "            input_size=(\n",
      "                288,\n",
      "                384,\n",
      "            ),\n",
      "            heatmap_size=(\n",
      "                72,\n",
      "                96,\n",
      "            ),\n",
      "            sigma=3),\n",
      "        _scope_='mmpose'),\n",
      "    dict(type='PackPoseInputs', _scope_='mmpose'),\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='LoadImage', _scope_='mmpose'),\n",
      "    dict(type='GetBBoxCenterScale', _scope_='mmpose'),\n",
      "    dict(\n",
      "        type='TopdownAffine',\n",
      "        input_size=(\n",
      "            288,\n",
      "            384,\n",
      "        ),\n",
      "        use_udp=True,\n",
      "        _scope_='mmpose'),\n",
      "    dict(type='PackPoseInputs', _scope_='mmpose'),\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True, _scope_='mmpose'),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root=\n",
      "        '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/',\n",
      "        data_mode='topdown',\n",
      "        ann_file=\n",
      "        '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/annotations/person_keypoints_train.json',\n",
      "        data_prefix=dict(img='images/train'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImage'),\n",
      "            dict(type='GetBBoxCenterScale'),\n",
      "            dict(type='RandomFlip', direction='horizontal'),\n",
      "            dict(type='RandomHalfBody'),\n",
      "            dict(type='RandomBBoxTransform'),\n",
      "            dict(type='TopdownAffine', input_size=(\n",
      "                288,\n",
      "                384,\n",
      "            ), use_udp=True),\n",
      "            dict(\n",
      "                type='GenerateTarget',\n",
      "                encoder=dict(\n",
      "                    type='UDPHeatmap',\n",
      "                    input_size=(\n",
      "                        288,\n",
      "                        384,\n",
      "                    ),\n",
      "                    heatmap_size=(\n",
      "                        72,\n",
      "                        96,\n",
      "                    ),\n",
      "                    sigma=3)),\n",
      "            dict(type='PackPoseInputs'),\n",
      "        ],\n",
      "        _scope_='mmpose'))\n",
      "val_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(\n",
      "        type='DefaultSampler', shuffle=False, round_up=False,\n",
      "        _scope_='mmpose'),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root=\n",
      "        '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/',\n",
      "        data_mode='topdown',\n",
      "        ann_file=\n",
      "        '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/annotations/person_keypoints_val.json',\n",
      "        bbox_file=\n",
      "        '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/person_detection_results/human_detection_val.json',\n",
      "        data_prefix=dict(img='images/val'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImage'),\n",
      "            dict(type='GetBBoxCenterScale'),\n",
      "            dict(type='TopdownAffine', input_size=(\n",
      "                288,\n",
      "                384,\n",
      "            ), use_udp=True),\n",
      "            dict(type='PackPoseInputs'),\n",
      "        ],\n",
      "        _scope_='mmpose'))\n",
      "test_dataloader = dict(\n",
      "    batch_size=16,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(\n",
      "        type='DefaultSampler', shuffle=False, round_up=False,\n",
      "        _scope_='mmpose'),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root=\n",
      "        '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/',\n",
      "        data_mode='topdown',\n",
      "        ann_file=\n",
      "        '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/annotations/person_keypoints_test.json',\n",
      "        bbox_file=\n",
      "        '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/person_detection_results/human_detection_test.json',\n",
      "        data_prefix=dict(img='images/test'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImage'),\n",
      "            dict(type='GetBBoxCenterScale'),\n",
      "            dict(type='TopdownAffine', input_size=(\n",
      "                288,\n",
      "                384,\n",
      "            ), use_udp=True),\n",
      "            dict(type='PackPoseInputs'),\n",
      "        ],\n",
      "        _scope_='mmpose'))\n",
      "val_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file=\n",
      "    '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/annotations/person_keypoints_val.json',\n",
      "    _scope_='mmpose')\n",
      "test_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file=\n",
      "    '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/annotations/person_keypoints_test.json',\n",
      "    _scope_='mmpose')\n",
      "work_dir = './mmengine_workdir/pose_estimator_2d_synthetic_cabin_1m'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgentlerainsky\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/mmengine_workdir/pose_estimator_2d_synthetic_cabin_1m/20231118_182407/vis_data/wandb/run-20231118_182414-x5osztvm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gentlerainsky/uncategorized/runs/x5osztvm' target=\"_blank\">valiant-sponge-73</a></strong> to <a href='https://wandb.ai/gentlerainsky/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gentlerainsky/uncategorized' target=\"_blank\">https://wandb.ai/gentlerainsky/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gentlerainsky/uncategorized/runs/x5osztvm' target=\"_blank\">https://wandb.ai/gentlerainsky/uncategorized/runs/x5osztvm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 18:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "11/18 18:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) PoseVisualizationHook              \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) PoseVisualizationHook              \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmpose/datasets/datasets/utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/coco.py\" does not exist. A matched config file \"/opt/conda/lib/python3.10/site-packages/mmpose/.mim/configs/_base_/datasets/coco.py\" will be used instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.21s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.67s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.40s)\n",
      "creating index...\n",
      "index created!\n",
      "11/18 18:24:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmpose/pretrain_models/hrnet_w48-8ef0771d.pth\n",
      "11/18 18:24:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/pretrain_models/hrnet_w48-8ef0771d.pth\n",
      "11/18 18:24:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.0.0.0.conv1.weight, head.0.0.0.bn1.weight, head.0.0.0.bn1.bias, head.0.0.0.bn1.running_mean, head.0.0.0.bn1.running_var, head.0.0.0.conv2.weight, head.0.0.0.bn2.weight, head.0.0.0.bn2.bias, head.0.0.0.bn2.running_mean, head.0.0.0.bn2.running_var, head.0.0.0.conv3.weight, head.0.0.0.bn3.weight, head.0.0.0.bn3.bias, head.0.0.0.bn3.running_mean, head.0.0.0.bn3.running_var, head.0.0.0.downsample.0.weight, head.0.0.0.downsample.1.weight, head.0.0.0.downsample.1.bias, head.0.0.0.downsample.1.running_mean, head.0.0.0.downsample.1.running_var, head.0.1.0.conv1.weight, head.0.1.0.bn1.weight, head.0.1.0.bn1.bias, head.0.1.0.bn1.running_mean, head.0.1.0.bn1.running_var, head.0.1.0.conv2.weight, head.0.1.0.bn2.weight, head.0.1.0.bn2.bias, head.0.1.0.bn2.running_mean, head.0.1.0.bn2.running_var, head.0.1.0.conv3.weight, head.0.1.0.bn3.weight, head.0.1.0.bn3.bias, head.0.1.0.bn3.running_mean, head.0.1.0.bn3.running_var, head.0.1.0.downsample.0.weight, head.0.1.0.downsample.1.weight, head.0.1.0.downsample.1.bias, head.0.1.0.downsample.1.running_mean, head.0.1.0.downsample.1.running_var, head.0.2.0.conv1.weight, head.0.2.0.bn1.weight, head.0.2.0.bn1.bias, head.0.2.0.bn1.running_mean, head.0.2.0.bn1.running_var, head.0.2.0.conv2.weight, head.0.2.0.bn2.weight, head.0.2.0.bn2.bias, head.0.2.0.bn2.running_mean, head.0.2.0.bn2.running_var, head.0.2.0.conv3.weight, head.0.2.0.bn3.weight, head.0.2.0.bn3.bias, head.0.2.0.bn3.running_mean, head.0.2.0.bn3.running_var, head.0.2.0.downsample.0.weight, head.0.2.0.downsample.1.weight, head.0.2.0.downsample.1.bias, head.0.2.0.downsample.1.running_mean, head.0.2.0.downsample.1.running_var, head.1.0.0.conv1.weight, head.1.0.0.bn1.weight, head.1.0.0.bn1.bias, head.1.0.0.bn1.running_mean, head.1.0.0.bn1.running_var, head.1.0.0.conv2.weight, head.1.0.0.bn2.weight, head.1.0.0.bn2.bias, head.1.0.0.bn2.running_mean, head.1.0.0.bn2.running_var, head.1.0.0.conv3.weight, head.1.0.0.bn3.weight, head.1.0.0.bn3.bias, head.1.0.0.bn3.running_mean, head.1.0.0.bn3.running_var, head.1.0.0.downsample.0.weight, head.1.0.0.downsample.1.weight, head.1.0.0.downsample.1.bias, head.1.0.0.downsample.1.running_mean, head.1.0.0.downsample.1.running_var, head.1.1.0.conv1.weight, head.1.1.0.bn1.weight, head.1.1.0.bn1.bias, head.1.1.0.bn1.running_mean, head.1.1.0.bn1.running_var, head.1.1.0.conv2.weight, head.1.1.0.bn2.weight, head.1.1.0.bn2.bias, head.1.1.0.bn2.running_mean, head.1.1.0.bn2.running_var, head.1.1.0.conv3.weight, head.1.1.0.bn3.weight, head.1.1.0.bn3.bias, head.1.1.0.bn3.running_mean, head.1.1.0.bn3.running_var, head.1.1.0.downsample.0.weight, head.1.1.0.downsample.1.weight, head.1.1.0.downsample.1.bias, head.1.1.0.downsample.1.running_mean, head.1.1.0.downsample.1.running_var, head.2.0.0.conv1.weight, head.2.0.0.bn1.weight, head.2.0.0.bn1.bias, head.2.0.0.bn1.running_mean, head.2.0.0.bn1.running_var, head.2.0.0.conv2.weight, head.2.0.0.bn2.weight, head.2.0.0.bn2.bias, head.2.0.0.bn2.running_mean, head.2.0.0.bn2.running_var, head.2.0.0.conv3.weight, head.2.0.0.bn3.weight, head.2.0.0.bn3.bias, head.2.0.0.bn3.running_mean, head.2.0.0.bn3.running_var, head.2.0.0.downsample.0.weight, head.2.0.0.downsample.1.weight, head.2.0.0.downsample.1.bias, head.2.0.0.downsample.1.running_mean, head.2.0.0.downsample.1.running_var, head.3.0.0.conv1.weight, head.3.0.0.bn1.weight, head.3.0.0.bn1.bias, head.3.0.0.bn1.running_mean, head.3.0.0.bn1.running_var, head.3.0.0.conv2.weight, head.3.0.0.bn2.weight, head.3.0.0.bn2.bias, head.3.0.0.bn2.running_mean, head.3.0.0.bn2.running_var, head.3.0.0.conv3.weight, head.3.0.0.bn3.weight, head.3.0.0.bn3.bias, head.3.0.0.bn3.running_mean, head.3.0.0.bn3.running_var, head.3.0.0.downsample.0.weight, head.3.0.0.downsample.1.weight, head.3.0.0.downsample.1.bias, head.3.0.0.downsample.1.running_mean, head.3.0.0.downsample.1.running_var, fc.weight, fc.bias, stage4.2.fuse_layers.1.0.0.0.weight, stage4.2.fuse_layers.1.0.0.1.weight, stage4.2.fuse_layers.1.0.0.1.bias, stage4.2.fuse_layers.1.0.0.1.running_mean, stage4.2.fuse_layers.1.0.0.1.running_var, stage4.2.fuse_layers.1.2.0.weight, stage4.2.fuse_layers.1.2.1.weight, stage4.2.fuse_layers.1.2.1.bias, stage4.2.fuse_layers.1.2.1.running_mean, stage4.2.fuse_layers.1.2.1.running_var, stage4.2.fuse_layers.1.3.0.weight, stage4.2.fuse_layers.1.3.1.weight, stage4.2.fuse_layers.1.3.1.bias, stage4.2.fuse_layers.1.3.1.running_mean, stage4.2.fuse_layers.1.3.1.running_var, stage4.2.fuse_layers.2.0.0.0.weight, stage4.2.fuse_layers.2.0.0.1.weight, stage4.2.fuse_layers.2.0.0.1.bias, stage4.2.fuse_layers.2.0.0.1.running_mean, stage4.2.fuse_layers.2.0.0.1.running_var, stage4.2.fuse_layers.2.0.1.0.weight, stage4.2.fuse_layers.2.0.1.1.weight, stage4.2.fuse_layers.2.0.1.1.bias, stage4.2.fuse_layers.2.0.1.1.running_mean, stage4.2.fuse_layers.2.0.1.1.running_var, stage4.2.fuse_layers.2.1.0.0.weight, stage4.2.fuse_layers.2.1.0.1.weight, stage4.2.fuse_layers.2.1.0.1.bias, stage4.2.fuse_layers.2.1.0.1.running_mean, stage4.2.fuse_layers.2.1.0.1.running_var, stage4.2.fuse_layers.2.3.0.weight, stage4.2.fuse_layers.2.3.1.weight, stage4.2.fuse_layers.2.3.1.bias, stage4.2.fuse_layers.2.3.1.running_mean, stage4.2.fuse_layers.2.3.1.running_var, stage4.2.fuse_layers.3.0.0.0.weight, stage4.2.fuse_layers.3.0.0.1.weight, stage4.2.fuse_layers.3.0.0.1.bias, stage4.2.fuse_layers.3.0.0.1.running_mean, stage4.2.fuse_layers.3.0.0.1.running_var, stage4.2.fuse_layers.3.0.1.0.weight, stage4.2.fuse_layers.3.0.1.1.weight, stage4.2.fuse_layers.3.0.1.1.bias, stage4.2.fuse_layers.3.0.1.1.running_mean, stage4.2.fuse_layers.3.0.1.1.running_var, stage4.2.fuse_layers.3.0.2.0.weight, stage4.2.fuse_layers.3.0.2.1.weight, stage4.2.fuse_layers.3.0.2.1.bias, stage4.2.fuse_layers.3.0.2.1.running_mean, stage4.2.fuse_layers.3.0.2.1.running_var, stage4.2.fuse_layers.3.1.0.0.weight, stage4.2.fuse_layers.3.1.0.1.weight, stage4.2.fuse_layers.3.1.0.1.bias, stage4.2.fuse_layers.3.1.0.1.running_mean, stage4.2.fuse_layers.3.1.0.1.running_var, stage4.2.fuse_layers.3.1.1.0.weight, stage4.2.fuse_layers.3.1.1.1.weight, stage4.2.fuse_layers.3.1.1.1.bias, stage4.2.fuse_layers.3.1.1.1.running_mean, stage4.2.fuse_layers.3.1.1.1.running_var, stage4.2.fuse_layers.3.2.0.0.weight, stage4.2.fuse_layers.3.2.0.1.weight, stage4.2.fuse_layers.3.2.0.1.bias, stage4.2.fuse_layers.3.2.0.1.running_mean, stage4.2.fuse_layers.3.2.0.1.running_var\n",
      "\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288-70d7ab01_20220913.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
      "\n",
      "11/18 18:24:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from https://download.openmmlab.com/mmpose/v1/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288-70d7ab01_20220913.pth\n",
      "11/18 18:24:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "11/18 18:24:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "11/18 18:24:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspace/mmengine_workdir/pose_estimator_2d_synthetic_cabin_1m.\n",
      "11/18 18:25:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  50/4688]  lr: 4.954910e-05  eta: 9:05:10  time: 0.698490  data_time: 0.039475  memory: 7744  loss: 0.001507  loss_kpt: 0.001507  acc_pose: 0.514288\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pose_estimator_2d \u001b[39m=\u001b[39m PoseEstimator2D(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     config_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msrc/modules/pose_estimator_2d/config/hrnet.py\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# config_path='src/modules/pose_estimator_2d/config/test_config.py',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     log_level\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# pose_estimator_2d.load_pretrained()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# pose_estimator_2d_result = pose_estimator_2d.inference(img_path, bbox.detach().cpu().numpy(), bbox_format='xywh')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# keypoints_2D = pose_estimator_2d_result[0].pred_instances['keypoints'][0]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# print(keypoints_2D)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tk/Documents/Projects/pose_estimation_3d/script/pose_estimation_2d/synthetic_cabin_1m/pose_estimator_2d_synthetic_cabin_1m.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m pose_estimator_2d\u001b[39m.\u001b[39;49mfinetune()\n",
      "File \u001b[0;32m/workspace/src/modules/pose_estimator_2d/pose_estimator_2d.py:95\u001b[0m, in \u001b[0;36mPoseEstimator2D.finetune\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_config()\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 95\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunner\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     96\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mwork_dir, \u001b[39m'\u001b[39m\u001b[39mlast_checkpoint\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     97\u001b[0m     filepath \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadline()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:1735\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[39m# Maybe compile the model according to options in self.cfg.compile\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[39m# This must be called **AFTER** model has been wrapped.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_compile(\u001b[39m'\u001b[39m\u001b[39mtrain_step\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1735\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_loop\u001b[39m.\u001b[39;49mrun()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_run\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1737\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:96\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mbefore_train\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_epochs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_epoch()\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decide_current_val_interval()\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mval_loop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_begin\n\u001b[1;32m    101\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:112\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m idx, data_batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_iter(idx, data_batch)\n\u001b[1;32m    114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_train_epoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epoch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/loops.py:131\u001b[0m, in \u001b[0;36mEpochBasedTrainLoop.run_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39m# Enable gradient accumulation mode and avoid unnecessary gradient\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m# synchronization during gradient accumulation process.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m# outputs should be a dict of loss.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain_step(\n\u001b[1;32m    129\u001b[0m     data_batch, optim_wrapper\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner\u001b[39m.\u001b[39moptim_wrapper)\n\u001b[0;32m--> 131\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunner\u001b[39m.\u001b[39;49mcall_hook(\n\u001b[1;32m    132\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mafter_train_iter\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    133\u001b[0m     batch_idx\u001b[39m=\u001b[39;49midx,\n\u001b[1;32m    134\u001b[0m     data_batch\u001b[39m=\u001b[39;49mdata_batch,\n\u001b[1;32m    135\u001b[0m     outputs\u001b[39m=\u001b[39;49moutputs)\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/runner/runner.py:1797\u001b[0m, in \u001b[0;36mRunner.call_hook\u001b[0;34m(self, fn_name, **kwargs)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(hook, fn_name):\n\u001b[1;32m   1796\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1797\u001b[0m         \u001b[39mgetattr\u001b[39;49m(hook, fn_name)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1798\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1799\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/hooks/runtime_info_hook.py:120\u001b[0m, in \u001b[0;36mRuntimeInfoHook.after_train_iter\u001b[0;34m(self, runner, batch_idx, data_batch, outputs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m outputs\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 120\u001b[0m         runner\u001b[39m.\u001b[39;49mmessage_hub\u001b[39m.\u001b[39;49mupdate_scalar(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain/\u001b[39;49m\u001b[39m{\u001b[39;49;00mkey\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/logging/message_hub.py:132\u001b[0m, in \u001b[0;36mMessageHub.update_scalar\u001b[0;34m(self, key, value, count, resumed)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update :attr:_log_scalars.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[39mUpdate ``HistoryBuffer`` in :attr:`_log_scalars`. If corresponding key\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m        could be resumed. Defaults to True.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_resumed_keys(key, resumed)\n\u001b[0;32m--> 132\u001b[0m checked_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_valid_value(value)\n\u001b[1;32m    133\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(count, \u001b[39mint\u001b[39m), (\n\u001b[1;32m    134\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe type of count must be int. but got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(count)\u001b[39m:\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_scalars:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmengine/logging/message_hub.py:332\u001b[0m, in \u001b[0;36mMessageHub._get_valid_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     \u001b[39m# check whether value is torch.Tensor but don't want\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[39m# to import torch in this file\u001b[39;00m\n\u001b[1;32m    331\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m'\u001b[39m\u001b[39mnumel\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 332\u001b[0m     value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    333\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n"
     ]
    }
   ],
   "source": [
    "from src.modules.pose_estimator_2d.pose_estimator_2d import PoseEstimator2D\n",
    "\n",
    "pose_estimator_2d = PoseEstimator2D(\n",
    "    config_path='src/modules/pose_estimator_2d/config/hrnet.py',\n",
    "    pretrained_path='https://download.openmmlab.com/mmpose/v1/'\\\n",
    "        'body_2d_keypoint/topdown_heatmap/coco/'\\\n",
    "            'td-hm_hrnet-w48_udp-8xb32-210e_coco-384x288-70d7ab01_20220913.pth',\n",
    "    checkpoint_path=\"./mmengine_workdir/pose_estimator_2d_synthetic_cabin_1m/best_coco_AP_epoch_0.pth\",\n",
    "    data_root_path='/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/',\n",
    "    device='cuda:0',\n",
    "    working_directory='./mmengine_workdir/pose_estimator_2d_synthetic_cabin_1m',\n",
    "    log_level='INFO'\n",
    ")\n",
    "\n",
    "# pose_estimator_2d.load_pretrained()\n",
    "# pose_estimator_2d_result = pose_estimator_2d.inference(img_path, bbox.detach().cpu().numpy(), bbox_format='xywh')\n",
    "# keypoints_2D = pose_estimator_2d_result[0].pred_instances['keypoints'][0]\n",
    "# print(keypoints_2D)\n",
    "pose_estimator_2d.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
