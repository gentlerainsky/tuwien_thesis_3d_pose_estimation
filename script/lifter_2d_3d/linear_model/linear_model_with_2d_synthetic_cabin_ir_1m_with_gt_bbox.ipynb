{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf saved_lifter_2d_3d_model/synthetic_cabin_bw/A_Pillar_Codriver/prediction/linear_model/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping problematic image 262501\n",
      "skipping problematic image 278126\n",
      "skipping problematic image 293751\n",
      "skipping problematic image 309376\n",
      "skipping problematic image 325001\n",
      "skipping problematic image 340626\n",
      "skipping problematic image 356251\n",
      "skipping problematic image 371876\n",
      "skipping problematic image 512501\n",
      "skipping problematic image 528126\n",
      "skipping problematic image 543751\n",
      "skipping problematic image 559376\n",
      "skipping problematic image 575001\n",
      "skipping problematic image 590626\n",
      "skipping problematic image 606251\n",
      "skipping problematic image 621876\n",
      "skipping problematic image 762501\n",
      "skipping problematic image 778126\n",
      "skipping problematic image 793751\n",
      "skipping problematic image 809376\n",
      "skipping problematic image 825001\n",
      "skipping problematic image 840626\n",
      "skipping problematic image 856251\n",
      "skipping problematic image 871876\n",
      "skipping problematic image 387501\n",
      "skipping problematic image 403126\n",
      "skipping problematic image 418751\n",
      "skipping problematic image 434376\n",
      "skipping problematic image 637501\n",
      "skipping problematic image 653126\n",
      "skipping problematic image 668751\n",
      "skipping problematic image 684376\n",
      "skipping problematic image 887501\n",
      "skipping problematic image 903126\n",
      "skipping problematic image 918751\n",
      "skipping problematic image 934376\n",
      "skipping problematic image 450001\n",
      "skipping problematic image 465626\n",
      "skipping problematic image 481251\n",
      "skipping problematic image 496876\n",
      "skipping problematic image 700001\n",
      "skipping problematic image 715626\n",
      "skipping problematic image 731251\n",
      "skipping problematic image 746876\n",
      "skipping problematic image 950001\n",
      "skipping problematic image 964725\n",
      "train_dataset 74976 val_dataset 37488 test_dataset 30339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type          | Params\n",
      "----------------------------------------\n",
      "0 | model | BaselineModel | 4.3 M \n",
      "----------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.146    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf785c4d849486aa523576b8790c563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #0\n",
      "val MPJPE from: 0 batches : 5789.471626281738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b95692897384b65b6b8368cff677d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd970b9dd7164f3c903cd2741eefa58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #1\n",
      "training loss from 5855 batches: 235.08428116062584\n",
      "val MPJPE from: 0 batches : 276.52114629745483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcbfffbe58c4e6fb76a204b6ec9c922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #2\n",
      "training loss from 5855 batches: 175.08841517845042\n",
      "val MPJPE from: 0 batches : 273.79822731018066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dca133a6bc4e798f89c4f86e08e5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #3\n",
      "training loss from 5855 batches: 172.43578189921928\n",
      "val MPJPE from: 0 batches : 272.661030292511\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261f0130063e4db2a72cd2b3888f17b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #4\n",
      "training loss from 5855 batches: 171.44271128458612\n",
      "val MPJPE from: 0 batches : 273.2143998146057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a087198029489bb8288349feffd4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #5\n",
      "training loss from 5855 batches: 170.96020269607703\n",
      "val MPJPE from: 0 batches : 272.3498046398163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Received SIGTERM: 15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.modules.lifter_2d_3d.model.linear_model.linear_model import BaselineModel\n",
    "from src.modules.lifter_2d_3d.dataset.simple_keypoint_dataset import SimpleKeypointDataset\n",
    "from src.modules.lifter_2d_3d.model.linear_model.lit_linear_model import LitSimpleBaselineLinear\n",
    "from src.modules.utils.visualization import generate_connection_line, get_sample_from_loader, visualize_pose\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "\n",
    "dataset_root = Path('/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/')\n",
    "\n",
    "train_dataset = SimpleKeypointDataset(\n",
    "    prediction_file=(\n",
    "        dataset_root / \"keypoint_detection_results/keypoint_detection_with_ground_truth_bbox_train.json\"\n",
    "        ).as_posix(),\n",
    "    annotation_file=(dataset_root / \"annotations/person_keypoints_train.json\").as_posix(),\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "val_dataset = SimpleKeypointDataset(\n",
    "    prediction_file=(\n",
    "        dataset_root / \"keypoint_detection_results/keypoint_detection_with_ground_truth_bbox_val.json\"\n",
    "        ).as_posix(),\n",
    "    annotation_file=(dataset_root / \"annotations/person_keypoints_val.json\").as_posix(),\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "test_dataset = SimpleKeypointDataset(\n",
    "    prediction_file=(\n",
    "        dataset_root / \"keypoint_detection_results/keypoint_detection_with_ground_truth_bbox_test.json\"\n",
    "        ).as_posix(),\n",
    "    annotation_file=(dataset_root / \"annotations/person_keypoints_test.json\").as_posix(),\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    'train_dataset', len(train_dataset),\n",
    "    'val_dataset', len(val_dataset),\n",
    "    'test_dataset', len(test_dataset)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, drop_last=True, shuffle=True, num_workers=24)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, drop_last=True, num_workers=24)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=24)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss',mode='min', save_top_k=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "lit_model = LitSimpleBaselineLinear(exclude_ankle=True)\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "saved_model_path = './saved_lifter_2d_3d_model/synthetic_cabin_ir_1m/A_Pillar_Codriver/prediction/linear_model/'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trainer = pl.Trainer(\n",
    "    # max_steps=10,\n",
    "    max_epochs=200,\n",
    "    callbacks=[model_checkpoint, early_stopping],\n",
    "    accelerator=device,\n",
    "    check_val_every_n_epoch=5,\n",
    "    default_root_dir=saved_model_path,\n",
    "    gradient_clip_val=1.0\n",
    ")\n",
    "trainer.fit(lit_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint_path = model_checkpoint.best_model_path\n",
    "trainer.test(ckpt_path=best_checkpoint_path, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample_from_loader(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_connection_line(sample['keypoints_3d'])\n",
    "pose_df = pd.DataFrame(results)\n",
    "visualize_pose(pose_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model.to(device)\n",
    "model.eval()\n",
    "estimated_pose = model(torch.flatten(torch.tensor(sample['keypoints_2d'])).unsqueeze(0).float().to(device), 0)\n",
    "estimated_pose_df = pd.DataFrame(generate_connection_line(estimated_pose[0].cpu().reshape([-1, 3]).detach().numpy()))\n",
    "visualize_pose(estimated_pose_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
