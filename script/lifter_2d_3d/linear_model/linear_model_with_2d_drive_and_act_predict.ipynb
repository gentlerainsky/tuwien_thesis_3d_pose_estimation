{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf saved_lifter_2d_3d_model/drive_and_act/prediction/linear_model/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly\n",
    "import plotly.express as px\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.modules.lifter_2d_3d.model.linear_model.linear_model import BaselineModel\n",
    "from src.modules.lifter_2d_3d.dataset.drive_and_act_keypoint_dataset import DriveAndActKeypointDataset\n",
    "from src.modules.lifter_2d_3d.model.linear_model.lit_linear_model import LitSimpleBaselineLinear\n",
    "from src.modules.utils.visualization import generate_connection_line, get_sample_from_loader, visualize_pose\n",
    "from IPython.display import display\n",
    "\n",
    "pl.seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping problematic image 15783\n",
      "skipping problematic image 17258\n",
      "skipping problematic image 17259\n",
      "skipping problematic image 21271\n",
      "skipping problematic image 21272\n",
      "skipping problematic image 21273\n",
      "skipping problematic image 21274\n",
      "skipping problematic image 21275\n",
      "skipping problematic image 21276\n",
      "skipping problematic image 33527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset 26626 val_dataset 5103 test_dataset 8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type          | Params\n",
      "----------------------------------------\n",
      "0 | model | BaselineModel | 4.3 M \n",
      "----------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.105    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a3de22d49d42ca8d83c1f9bb244bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #0\n",
      "val MPJPE from: 0 batches : 2893.4974670410156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb810bada30f4de8818888f1c404371a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d64232513841c29a466b087cb76883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #1\n",
      "training loss from 2080 batches: 500.90740858577186\n",
      "val MPJPE from: 0 batches : 81.75816386938095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0874de8989894074ace1995f6feeb6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #2\n",
      "training loss from 2080 batches: 105.92415710338034\n",
      "val MPJPE from: 0 batches : 65.79479575157166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3d462b8f0f48f2afc99bc810a83d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #3\n",
      "training loss from 2080 batches: 89.79802378811515\n",
      "val MPJPE from: 0 batches : 63.843995332717896\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65693cf7702144769c286d49f51f5e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #4\n",
      "training loss from 2080 batches: 82.41014962371152\n",
      "val MPJPE from: 0 batches : 61.75178661942482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7dfa8175fd54302a04f40775c970572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #5\n",
      "training loss from 2080 batches: 78.28743477495244\n",
      "val MPJPE from: 0 batches : 59.86277014017105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DriveAndActKeypointDataset(\n",
    "    # prediction_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_train.json\",\n",
    "    # annotation_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_train.json\",\n",
    "    prediction_file=\"/root/data/processed/drive_and_act/keypoint_detection_results/keypoint_detection_train.json\",\n",
    "    annotation_file=\"/root/data/processed/drive_and_act/annotations/person_keypoints_train.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    actors=['vp1', 'vp2', 'vp3', 'vp4', 'vp5', 'vp6', 'vp7', 'vp8', 'vp9', 'vp10'],\n",
    "    exclude_ankle=True,\n",
    "    exclude_hip=True\n",
    ")\n",
    "val_dataset = DriveAndActKeypointDataset(\n",
    "    # prediction_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_val.json\",\n",
    "    # annotation_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_val.json\",\n",
    "    prediction_file=\"/root/data/processed/drive_and_act/keypoint_detection_results/keypoint_detection_val.json\",\n",
    "    annotation_file=\"//root/data/processed/drive_and_act/annotations/person_keypoints_val.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    actors=['vp11', 'vp12'],\n",
    "    exclude_ankle=True,\n",
    "    exclude_hip=True\n",
    ")\n",
    "test_dataset = DriveAndActKeypointDataset(\n",
    "    # prediction_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_test.json\",\n",
    "    # annotation_file=\"/root/data/processed/synthetic_cabin_bw/A_Pillar_Codriver/annotations/person_keypoints_test.json\",\n",
    "    prediction_file=\"/root/data/processed/drive_and_act/keypoint_detection_results/keypoint_detection_test.json\",\n",
    "    annotation_file=\"/root/data/processed/drive_and_act/annotations/person_keypoints_test.json\",\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    actors=['vp13', 'vp14', 'vp15'],\n",
    "    exclude_ankle=True,\n",
    "    exclude_hip=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    'train_dataset', len(train_dataset),\n",
    "    'val_dataset', len(val_dataset),\n",
    "    'test_dataset', len(test_dataset)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, drop_last=True, shuffle=True, num_workers=24)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, drop_last=True, num_workers=24)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=24)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss',mode='min', save_top_k=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "lit_model = LitSimpleBaselineLinear(exclude_ankle=True, exclude_hip=True, all_activities=train_dataset.activities)\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "# saved_model_path = './saved_lifter_2d_3d_model/synthetic_cabin_bw/A_Pillar_Codriver/prediction/linear_model/'\n",
    "saved_model_path = './saved_lifter_2d_3d_model/drive_and_act/prediction/linear_model'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trainer = pl.Trainer(\n",
    "    # max_steps=10,\n",
    "    max_epochs=200,\n",
    "    callbacks=[model_checkpoint, early_stopping],\n",
    "    accelerator=device,\n",
    "    check_val_every_n_epoch=5,\n",
    "    default_root_dir=saved_model_path,\n",
    "    gradient_clip_val=1.0\n",
    ")\n",
    "trainer.fit(lit_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint_path = model_checkpoint.best_model_path\n",
    "trainer.test(ckpt_path=best_checkpoint_path, dataloaders=test_loader)\n",
    "results = lit_model.evaluator.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lit_model.evaluator.pjpe).mean(axis=0) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results[2].values(), index=results[2].keys(), columns=['PJPE']).sort_values('PJPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "predictions = {}\n",
    "with open(\"/root/data/processed/drive_and_act/keypoint_detection_results/keypoint_detection_train.json\") as f:\n",
    "    data = json.loads(f.read())\n",
    "    for item in data:\n",
    "        predictions[item['image_id']] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_checkpoint_path = model_checkpoint.best_model_path\n",
    "# trainer.test(ckpt_path=best_checkpoint_path, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample_from_loader(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_keypoints = (sample[1].sum(axis=1) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_connection_line(sample[1],\n",
    "        np.argwhere(valid_keypoints).reshape(-1))\n",
    "pose_df = pd.DataFrame(results)\n",
    "visualize_pose(pose_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model.to(device)\n",
    "model.eval()\n",
    "estimated_pose = model(torch.flatten(torch.tensor(sample[0])).unsqueeze(0).float().to(device), 0)\n",
    "estimated_pose_df = pd.DataFrame(\n",
    "    generate_connection_line(\n",
    "        estimated_pose[0].cpu().reshape([-1, 3]).detach().numpy(),\n",
    "        # np.argwhere(valid_keypoints).reshape(-1)\n",
    "    )\n",
    ")\n",
    "visualize_pose(estimated_pose_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
