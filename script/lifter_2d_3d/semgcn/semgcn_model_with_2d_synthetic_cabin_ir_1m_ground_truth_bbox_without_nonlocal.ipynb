{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf saved_lifter_2d_3d_model/synthetic_cabin_bw/A_Pillar_Codriver/prediction/sem_gcn/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_with_ground_truth_bbox_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m pl\u001b[38;5;241m.\u001b[39mseed_everything(\u001b[38;5;241m1234\u001b[39m)\n\u001b[1;32m     19\u001b[0m dataset_root \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleKeypointDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeypoint_detection_results/keypoint_detection_with_ground_truth_bbox_train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mannotations/person_keypoints_train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_ankle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m SimpleKeypointDataset(\n\u001b[1;32m     31\u001b[0m     prediction_file\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m     32\u001b[0m         dataset_root \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoint_detection_results/keypoint_detection_with_ground_truth_bbox_val.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     exclude_ankle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m SimpleKeypointDataset(\n\u001b[1;32m     41\u001b[0m     prediction_file\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m     42\u001b[0m         dataset_root \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoint_detection_results/keypoint_detection_with_ground_truth_bbox_test.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     exclude_ankle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     48\u001b[0m )\n",
      "File \u001b[0;32m/workspace/src/modules/lifter_2d_3d/dataset/simple_keypoint_dataset.py:25\u001b[0m, in \u001b[0;36mSimpleKeypointDataset.__init__\u001b[0;34m(self, annotation_file, prediction_file, image_width, image_height, exclude_ankle, exclude_knee)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_knee \u001b[38;5;241m=\u001b[39m exclude_knee\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/src/modules/lifter_2d_3d/dataset/simple_keypoint_dataset.py:29\u001b[0m, in \u001b[0;36mSimpleKeypointDataset.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     28\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     30\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/keypoint_detection_results/keypoint_detection_with_ground_truth_bbox_train.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "# from src.modules.lifter_2d_3d.model.semgcn.sem_gcn import SemGCN\n",
    "from src.modules.lifter_2d_3d.dataset.simple_keypoint_dataset import SimpleKeypointDataset\n",
    "from src.modules.lifter_2d_3d.model.semgcn.lit_semgcn import LitSemGCN\n",
    "from IPython.display import display\n",
    "from src.modules.utils.visualization import generate_connection_line, get_sample_from_loader, visualize_pose\n",
    "from pathlib import Path\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "\n",
    "dataset_root = Path('/root/synthetic_cabin_1m/syntheticcabin_1mil/processed_syntheticCabin_1m/A_Pillar_Codriver/')\n",
    "\n",
    "train_dataset = SimpleKeypointDataset(\n",
    "    prediction_file=(\n",
    "        dataset_root / \"keypoint_detection_results/keypoint_detection_with_ground_truth_bbox_train.json\"\n",
    "        ).as_posix(),\n",
    "    annotation_file=(dataset_root / \"annotations/person_keypoints_train.json\").as_posix(),\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "val_dataset = SimpleKeypointDataset(\n",
    "    prediction_file=(\n",
    "        dataset_root / \"keypoint_detection_results/keypoint_detection_with_ground_truth_bbox_val.json\"\n",
    "        ).as_posix(),\n",
    "    annotation_file=(dataset_root / \"annotations/person_keypoints_val.json\").as_posix(),\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "\n",
    "test_dataset = SimpleKeypointDataset(\n",
    "    prediction_file=(\n",
    "        dataset_root / \"keypoint_detection_results/keypoint_detection_with_ground_truth_bbox_test.json\"\n",
    "        ).as_posix(),\n",
    "    annotation_file=(dataset_root / \"annotations/person_keypoints_test.json\").as_posix(),\n",
    "    image_width=1280,\n",
    "    image_height=1024,\n",
    "    exclude_ankle=True\n",
    ")\n",
    "print(\n",
    "    'train_dataset', len(train_dataset),\n",
    "    'val_dataset', len(val_dataset),\n",
    "    'test_dataset', len(test_dataset)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, drop_last=True, shuffle=True, num_workers=24)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, drop_last=True, num_workers=24)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=24)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss',mode='min', save_top_k=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "lit_model = LitSemGCN(exclude_ankle=True)\n",
    "# ------------\n",
    "# training\n",
    "# ------------\n",
    "saved_model_path = './saved_lifter_2d_3d_model/synthetic_cabin_ir_1m/A_Pillar_Codriver/prediction/sem_gcn/'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trainer = pl.Trainer(\n",
    "    # max_steps=10,\n",
    "    max_epochs=200,\n",
    "    callbacks=[model_checkpoint, early_stopping],\n",
    "    accelerator=device,\n",
    "    check_val_every_n_epoch=5,\n",
    "    default_root_dir=saved_model_path,\n",
    "    # gradient_clip_val=1.0\n",
    ")\n",
    "trainer.fit(lit_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint_path = model_checkpoint.best_model_path\n",
    "trainer.test(ckpt_path=best_checkpoint_path, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = get_sample_from_loader(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_connection_line(sample['keypoints_3d'])\n",
    "pose_df = pd.DataFrame(results)\n",
    "visualize_pose(pose_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model.to(device)\n",
    "model.eval()\n",
    "estimated_pose = model(torch.flatten(torch.tensor(sample['keypoints_2d'])).unsqueeze(0).float().to(device), 0)\n",
    "estimated_pose_df = pd.DataFrame(generate_connection_line(estimated_pose[0].cpu().reshape([-1, 3]).detach().numpy()))\n",
    "visualize_pose(estimated_pose_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
