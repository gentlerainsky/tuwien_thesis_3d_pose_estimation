{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping problematic image 15783\n",
      "skipping problematic image 17258\n",
      "skipping problematic image 17259\n",
      "skipping problematic image 21271\n",
      "skipping problematic image 21272\n",
      "skipping problematic image 21273\n",
      "skipping problematic image 21274\n",
      "skipping problematic image 21275\n",
      "skipping problematic image 21276\n",
      "skipping problematic image 33527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: saved_lifter_2d_3d_model/linear_model/drive_and_act/A_Pillar_Codriver/predicted_2d/all_actors/lightning_logs\n",
      "\n",
      "  | Name  | Type          | Params\n",
      "----------------------------------------\n",
      "0 | model | BaselineModel | 4.3 M \n",
      "----------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.105    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset 22885 val_dataset 6240 test_dataset 11018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1e85efe6694bab9bcc0a8aae994f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #0\n",
      "val MPJPE from: 128 samples : 1823.7416744232178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45146f2ffdbc4d5da960e775f5056950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ada7842fd80485883988e8681f2ee35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #1\n",
      "training loss from 1785 batches: 588.3779263713446\n",
      "val MPJPE from: 6208 samples : 144.06833052635193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf354e39b1f4cc6a9be93d434f72a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #2\n",
      "training loss from 1785 batches: 229.36615631693886\n",
      "val MPJPE from: 6208 samples : 137.09355890750885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9ed23915744243a70628b00eef665b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #3\n",
      "training loss from 1785 batches: 217.5445686785781\n",
      "val MPJPE from: 6208 samples : 134.54005122184753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20485a7e02594c1d966f4cb2f07bf7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #4\n",
      "training loss from 1785 batches: 212.7740729673236\n",
      "val MPJPE from: 6208 samples : 131.95863366127014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39297a5fcc934c70b5537ac4cc331bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #5\n",
      "training loss from 1785 batches: 209.33982205658066\n",
      "val MPJPE from: 6208 samples : 130.0395429134369\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46cb252338243c5a5d18c6fbc983d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #6\n",
      "training loss from 1785 batches: 206.60416691744027\n",
      "val MPJPE from: 6208 samples : 128.24515998363495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc4a0c67ede485bb199a9394eb0f64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #7\n",
      "training loss from 1785 batches: 204.46909599277484\n",
      "val MPJPE from: 6208 samples : 130.81276416778564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d84dc9d4e844318bc481ddc44f82600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check #8\n",
      "training loss from 1785 batches: 202.74849401301697\n",
      "val MPJPE from: 6208 samples : 131.9219022989273\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from modules.lifter_2d_3d.dataset.drive_and_act_keypoint_dataset import DriveAndActKeypointDataset\n",
    "# from modules.lifter_2d_3d.model.linear_model.lit_linear_model import LitSimpleBaselineLinear\n",
    "from modules.lifter_2d_3d.model.semgcn.lit_semgcn import LitSemGCN\n",
    "from modules.utils.visualization import (\n",
    "    plot_samples\n",
    ")\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "\n",
    "# ------------\n",
    "# dataset path\n",
    "# ------------\n",
    "dataset_root_path = Path('/root/data/processed/drive_and_act/')\n",
    "keypoint_2d_path = dataset_root_path / 'keypoint_detection_results'\n",
    "keypoint_3d_path = dataset_root_path / 'annotations'\n",
    "bbox_file = dataset_root_path / 'person_detection_results'\n",
    "# ------------\n",
    "# model\n",
    "# ------------\n",
    "image_width = 1280\n",
    "image_height = 1024\n",
    "batch_size = 64\n",
    "max_epoch = 200\n",
    "val_check_period = 5\n",
    "early_stopping_patience = 5\n",
    "# ------------\n",
    "# saved model path\n",
    "# ------------\n",
    "saved_model_path = './saved_lifter_2d_3d_model/linear_model/drive_and_act/A_Pillar_Codriver/predicted_2d/all_actors/'\n",
    "\n",
    "\n",
    "train_dataset = DriveAndActKeypointDataset(\n",
    "    prediction_file=(keypoint_2d_path / 'keypoint_detection_train.json').as_posix(),\n",
    "    annotation_file=(keypoint_3d_path / 'person_keypoints_train.json').as_posix(),\n",
    "    bbox_file=(bbox_file / 'human_detection_train.json').as_posix(),\n",
    "    image_width=image_width,\n",
    "    image_height=image_height,\n",
    "    # actors=['vp1', 'vp4', 'vp5', 'vp6', 'vp7', 'vp8', 'vp9', 'vp10', 'vp15'],\n",
    "    actors=['vp1', 'vp2', 'vp3', 'vp4', 'vp5', 'vp6', 'vp7', 'vp8'],\n",
    "    exclude_ankle=True,\n",
    "    exclude_knee=True,\n",
    "    is_normalize_to_bbox=True,\n",
    "    bbox_format='xyxy'\n",
    ")\n",
    "val_dataset = DriveAndActKeypointDataset(\n",
    "    prediction_file=(keypoint_2d_path / 'keypoint_detection_train.json').as_posix(),\n",
    "    annotation_file=(keypoint_3d_path / 'person_keypoints_train.json').as_posix(),\n",
    "    bbox_file=(bbox_file / 'human_detection_train.json').as_posix(),\n",
    "    image_width=image_width,\n",
    "    image_height=image_height,\n",
    "    # actors=['vp2', 'vp3'],\n",
    "    actors=['vp9', 'vp10', 'vp15'],\n",
    "    exclude_ankle=True,\n",
    "    exclude_knee=True,\n",
    "    is_normalize_to_bbox=True,\n",
    "    bbox_format='xyxy'\n",
    ")\n",
    "test_dataset = DriveAndActKeypointDataset(\n",
    "    prediction_file=(keypoint_2d_path / 'keypoint_detection_train.json').as_posix(),\n",
    "    annotation_file=(keypoint_3d_path / 'person_keypoints_train.json').as_posix(),\n",
    "    bbox_file=(bbox_file / 'human_detection_train.json').as_posix(),\n",
    "    image_width=image_width,\n",
    "    image_height=image_height,\n",
    "    actors=['vp11', 'vp12', 'vp13', 'vp14'],\n",
    "    # actors=['vp13', 'vp14', 'vp15'],\n",
    "    exclude_ankle=True,\n",
    "    exclude_knee=True,\n",
    "    is_normalize_to_bbox=True,\n",
    "    bbox_format='xyxy'\n",
    ")\n",
    "all_activities = train_dataset.activities.union(val_dataset.activities).union(test_dataset.activities)\n",
    "lit_model = LitSemGCN(exclude_ankle=True, exclude_knee=True, all_activities=all_activities, is_silence=False)\n",
    "print(\n",
    "    'train_dataset', len(train_dataset),\n",
    "    'val_dataset', len(val_dataset),\n",
    "    'test_dataset', len(test_dataset)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=24)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=True, num_workers=24)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=24)\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss',mode='min', save_top_k=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=early_stopping_patience)\n",
    "\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trainer = pl.Trainer(\n",
    "    # max_steps=10,\n",
    "    max_epochs=max_epoch,\n",
    "    callbacks=[model_checkpoint, early_stopping],\n",
    "    accelerator=device,\n",
    "    check_val_every_n_epoch=val_check_period,\n",
    "    default_root_dir=saved_model_path,\n",
    "    gradient_clip_val=1.0\n",
    ")\n",
    "trainer.fit(lit_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{saved_model_path}/best_model_path.txt', 'w') as f:\n",
    "    f.writelines(model_checkpoint.best_model_path)\n",
    "best_checkpoint_path = model_checkpoint.best_model_path\n",
    "trainer.test(ckpt_path=best_checkpoint_path, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lit_model.test_history[0]['activities_mpjpe'], index=['mpjpe']).T.sort_values('mpjpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lit_model.test_history[0]['activities_mpjpe'], index=['mpjpe']).T.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(\n",
    "    dataset_root_path,\n",
    "    trainer.model,\n",
    "    test_loader,\n",
    "    'train',\n",
    "    img_figsize=(20, 10),\n",
    "    img_width=image_width,\n",
    "    img_height=image_height,\n",
    "    plot_figsize=(20.5, 10),\n",
    "    sample_idices=[1000, 2500, 6000],\n",
    "    is_plot_gt_skeleton=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
